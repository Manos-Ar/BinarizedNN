{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc865033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from models.binarized_modules import binarized\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# from binarized_modules import  BinarizeLinear,BinarizeConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86bde069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/earapidis/Fast-Crossbar-Sim/python')\n",
    "from crossbar import VectorSim, ParallelSim, _task\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b3bde3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/earapidis/BinarizedNN'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "236bd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62f8a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51fbfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a26c3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d875105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mnist_bnn import Net\n",
    "from models.lenet_5 import BinarizedLeNet5_BN as Net\n",
    "\n",
    "model = Net()\n",
    "if cuda:\n",
    "    torch.cuda.set_device(0)\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3117c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = os.path.join(models_path,f\"epoch_7.pth\")\n",
    "model_idx = 1\n",
    "models_path = os.path.abspath(f\"/home/earapidis/BinarizedNN/saved_models/lenet_5/model_{model_idx}\")\n",
    "model_path = os.path.join(models_path,f\"epoch_15.pth\")\n",
    "# model_path = os.path.join(models_path,f\"best.pth\")\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "if cuda:\n",
    "    torch.cuda.set_device(0)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43fba5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinarizedLeNet5_BN(\n",
       "  (conv1): BinarizeConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh1): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): BinarizeConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): BinarizeLinear(in_features=256, out_features=120, bias=True)\n",
       "  (bn_fc1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh3): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (fc2): BinarizeLinear(in_features=120, out_features=84, bias=True)\n",
       "  (bn_fc2): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh4): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (fc3): BinarizeLinear(in_features=84, out_features=10, bias=True)\n",
       "  (bn_fc3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5e1ca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(test_loader))\n",
    "print(f\"image shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fdc484eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=model.conv1(images)\n",
    "x=model.bn1(x)\n",
    "x=model.htanh1(x)\n",
    "x=model.pool1(x)\n",
    "x = x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0ed57961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = images\n",
    "# inputs = x\n",
    "inputs = binarized(inputs)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e6eb9a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 5, 5])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters = model.conv1.weight.data\n",
    "filters_b = binarized(filters)\n",
    "filters_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "38c44fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUT = 50\n",
    "# CIN = 6\n",
    "# Kh = 5\n",
    "# Kw = 5\n",
    "# filters = torch.randn(COUT,CIN,Kh,Kw)\n",
    "# filters = binarized(filters)\n",
    "\n",
    "COUT, CIN, Kh, Kw = filters.shape\n",
    "N, CIN, Hi,Wi = inputs.shape\n",
    "# Hi = 24\n",
    "# Wi = 24\n",
    "# N = 1\n",
    "padding = 0 \n",
    "Num_rows = 32\n",
    "Num_Columns = 32                    \n",
    "Hout = Hi + 2*padding - Kh + 1\n",
    "Wout = Wi + 2*padding - Kw + 1\n",
    "\n",
    "\n",
    "# filters = torch.randn(COUT, CIN, Kh, Kw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "19407a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 1, 0, 1, 0, 1, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def checkerboard_last_cols(arr: torch.Tensor, C: int) -> None:\n",
    "    \"\"\"\n",
    "    Overwrite the last C columns of `arr` in-place with a checkerboard pattern of 0s and 1s.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : torch.Tensor\n",
    "        Input 2D tensor of shape (n, m).\n",
    "    C : int\n",
    "        Number of columns at the right edge to turn into a checkerboard.\n",
    "    \"\"\"\n",
    "    n, m = arr.shape\n",
    "    if C > m:\n",
    "        raise ValueError(\"C cannot be larger than the number of columns m.\")\n",
    "    \n",
    "    # Create row and column indices\n",
    "    rows = torch.arange(n).view(-1, 1)                # shape: (n, 1)\n",
    "    cols = torch.arange(m - C, m).view(1, -1)         # shape: (1, C)\n",
    "\n",
    "    # Generate checkerboard pattern\n",
    "    pattern = (rows + cols) % 2\n",
    "\n",
    "    # Apply the pattern to the last C columns in-place\n",
    "    arr[:, -C:] = pattern\n",
    "\n",
    "# Example\n",
    "A = torch.ones((6, 8), dtype=torch.int)\n",
    "checkerboard_last_cols(A, C=5)\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9b88f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compliment(x):\n",
    "    x = x.clone()\n",
    "    neg = -1*x\n",
    "    pos = x\n",
    "\n",
    "    pos[pos==-1] = 0\n",
    "    neg[neg==-1] = 0\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4db5e20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "pos_inputs, neg_inputs = compliment(inputs)\n",
    "pos_filters, neg_filters = compliment(filters_b)\n",
    "\n",
    "print(pos_filters.shape)\n",
    "print(pos_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4357b472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 50])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = torch.empty((COUT,CIN,2*(Kh*Kw)))\n",
    "\n",
    "pos = pos_filters.reshape(pos_filters.shape[0],pos_filters.shape[1],-1)\n",
    "neg = neg_filters.reshape(neg_filters.shape[0],neg_filters.shape[1],-1)\n",
    "kernel_size = Kh*Kw\n",
    "\n",
    "for i in range(kernel_size):\n",
    "\n",
    "    new_weights[:,:,2*i] = pos[:,:,i]\n",
    "    new_weights[:,:,2*i+1] = neg[:,:,i]\n",
    "new_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "36c892f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24\n"
     ]
    }
   ],
   "source": [
    "print(Hout,Wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "24e5748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inputs = torch.empty((N,Hout,Wout,CIN,2*kernel_size))\n",
    "for ii in range(Hout):\n",
    "    for jj in range(Wout):\n",
    "        _pos_ = pos_inputs[:,:,ii:ii+Kh,jj:jj+Kw]\n",
    "        _neg_ = neg_inputs[:,:,ii:ii+Kh,jj:jj+Kw]\n",
    "        # print(_pos_.shape)\n",
    "        _pos_ = _pos_.reshape(_pos_.shape[0],_pos_.shape[1],-1)\n",
    "        _neg_ = _neg_.reshape(_neg_.shape[0],_neg_.shape[1],-1)\n",
    "        one_pixel = torch.empty(_pos_.shape[0],_pos_.shape[1],2*kernel_size)\n",
    "        for z in range(kernel_size):\n",
    "            one_pixel[:,:,2*z]=_pos_[:,:,z]\n",
    "            one_pixel[:,:,2*z+1]=_neg_[:,:,z]\n",
    "        new_inputs[:,ii,jj,:,:] = one_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "13463043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 24, 1, 50])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f30a235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(I,Kh, Kw, CIN):\n",
    "    out = 2*I - Kh*Kw*CIN\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2468f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = nn.functional.conv2d(inputs, filters_b, padding=0)\n",
    "# ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b517ce08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2d = torch.empty((N,COUT,Hout,Wout))\n",
    "\n",
    "for ii in range(Hout):\n",
    "    for jj in range(Wout):\n",
    "        one_pixel = new_inputs[:,ii,jj,:,:]\n",
    "        # print(one_pixel.shape)\n",
    "        out_1d = F.conv1d(one_pixel,new_weights)\n",
    "        out_1d = out_1d.squeeze(-1)\n",
    "        # print(out_1d.shape)\n",
    "        out_2d[:,:,ii,jj] = out_1d\n",
    "out_2d = get_output(out_2d,Kh,Kw,CIN)\n",
    "torch.equal(out_2d,ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "829e0764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 50])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2b6f4211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function math.ceil(x, /)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7ee6537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_conv_2d(crossbar_inputs,crossbar_weights,_COUT_,Total_dim):\n",
    "    _N_,_HOUT_,_WOUT_,crossbar_y,Num_rows = crossbar_inputs.shape\n",
    "    _,crossbar_x,_,Num_Columns = crossbar_weights.shape\n",
    "    output_conv_2d = torch.zeros(_N_,_COUT_,_HOUT_,_WOUT_)\n",
    "\n",
    "    columns_per_crossbar = math.floor(_COUT_/crossbar_x)\n",
    "\n",
    "    for ii in range(_HOUT_):\n",
    "        for jj in range(_WOUT_):\n",
    "            mac_out_columns = torch.zeros((_N_,_COUT_))\n",
    "            for cy in range(crossbar_y):\n",
    "                for cx in range(crossbar_x):\n",
    "                    tmp_x=crossbar_inputs[:,ii,jj,cy,:]\n",
    "                    tmp_w=crossbar_weights[cy,cx,:,:]\n",
    "                    checkerboard_last_cols(tmp_w,Num_Columns-columns_per_crossbar)\n",
    "                    # tmp_w=crossbar_weights\n",
    "                    # print(tmp_x.shape)\n",
    "                    # print(tmp_w.shape)\n",
    "                    # _out_ = torch.matmul(tmp_w,tmp_x)\n",
    "                    _out_ = torch.matmul(tmp_x,tmp_w)\n",
    "\n",
    "                    column_start_idx = cx*columns_per_crossbar\n",
    "                    if cx==crossbar_x-1:\n",
    "                        column_end_idx=Total_dim\n",
    "                    else:\n",
    "                        column_end_idx = (cx+1)*columns_per_crossbar\n",
    "                    \n",
    "                    mac_out_columns[:,column_start_idx:column_end_idx] += _out_[:,:columns_per_crossbar]\n",
    "            output_conv_2d[:,:,ii,jj]=mac_out_columns\n",
    "    return output_conv_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "144a5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cim_conv_2d(crossbar_inputs,crossbar_weights,_COUT_,Total_dim):\n",
    "#     _N_,_HOUT_,_WOUT_,crossbar_y,Num_rows = crossbar_inputs.shape\n",
    "#     _,crossbar_x,_,Num_Columns = crossbar_weights.shape\n",
    "#     output_conv_2d = torch.zeros(_N_,_COUT_,_HOUT_,_WOUT_)\n",
    "\n",
    "#     columns_per_crossbar = math.floor(_COUT_/crossbar_x)\n",
    "\n",
    "#     for ii in tqdm(range(_HOUT_)):\n",
    "#         for jj in tqdm(range(_WOUT_)):\n",
    "#             mac_out_columns = torch.zeros((_N_,_COUT_))\n",
    "#             for cy in range(crossbar_y):\n",
    "#                 for cx in range(crossbar_x):\n",
    "#                     tmp_x=crossbar_inputs[:,ii,jj,cy,:]\n",
    "#                     tmp_w=crossbar_weights[cy,cx,:,:]\n",
    "#                     checkerboard_last_cols(tmp_w,Num_Columns-columns_per_crossbar)\n",
    "#                     # tmp_w=crossbar_weights\n",
    "#                     # print(tmp_x.shape)\n",
    "#                     # print(tmp_w.shape)\n",
    "#                     # _out_ = torch.matmul(tmp_w,tmp_x)\n",
    "#                     # _out_ = torch.matmul(tmp_x,tmp_w)\n",
    "#                     _,_out_ = _task(((cy,cx),tmp_x),tmp_w,Num_rows,Num_rows,\"cs\",False)\n",
    "#                     _out_ = torch.from_numpy(_out_)\n",
    "\n",
    "#                     column_start_idx = cx*columns_per_crossbar\n",
    "#                     if cx==crossbar_x-1:\n",
    "#                         column_end_idx=Total_dim\n",
    "#                     else:\n",
    "#                         column_end_idx = (cx+1)*columns_per_crossbar\n",
    "                    \n",
    "#                     mac_out_columns[:,column_start_idx:column_end_idx] += _out_[:,:columns_per_crossbar]\n",
    "#             output_conv_2d[:,:,ii,jj]=mac_out_columns\n",
    "#     return output_conv_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1aa7536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_tile(cy, cx, tmp_x_np, tmp_w_np, Num_rows, Num_Columns, columns_per_crossbar, Total_dim, mode):\n",
    "    checkerboard_last_cols(tmp_w_np, tmp_w_np.shape[1] - columns_per_crossbar)\n",
    "    _, _out_np = _task(((cy, cx), tmp_x_np), tmp_w_np, Num_rows, Num_Columns, mode, False)\n",
    "\n",
    "    column_start_idx = cx * columns_per_crossbar\n",
    "    column_end_idx = Total_dim if tmp_w_np.shape[1] - columns_per_crossbar < columns_per_crossbar else (cx + 1) * columns_per_crossbar\n",
    "    return (cy, cx, column_start_idx, column_end_idx, _out_np[:, :columns_per_crossbar])\n",
    "\n",
    "def cim_conv_2d(crossbar_inputs, crossbar_weights, _COUT_, mode, Total_dim, max_workers=None):\n",
    "    _N_, _HOUT_, _WOUT_, crossbar_y, Num_rows = crossbar_inputs.shape\n",
    "    _, crossbar_x, _, Num_Columns = crossbar_weights.shape\n",
    "    output_conv_2d = torch.zeros(_N_, _COUT_, _HOUT_, _WOUT_)\n",
    "\n",
    "    columns_per_crossbar = math.floor(_COUT_ / crossbar_x)\n",
    "\n",
    "    # Preconvert weights to NumPy once (this is reused for each (ii, jj))\n",
    "    weights_np = [[crossbar_weights[cy, cx].numpy() for cx in range(crossbar_x)] for cy in range(crossbar_y)]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for ii in tqdm(range(_HOUT_)):\n",
    "            for jj in range(_WOUT_):\n",
    "                mac_out_columns = torch.zeros((_N_, _COUT_))\n",
    "                tasks = []\n",
    "\n",
    "                for cy in range(crossbar_y):\n",
    "                    for cx in range(crossbar_x):\n",
    "                        tmp_x = crossbar_inputs[:, ii, jj, cy, :].numpy()\n",
    "                        tmp_w = weights_np[cy][cx]\n",
    "                        tasks.append((cy, cx, tmp_x, tmp_w, Num_rows, Num_Columns, columns_per_crossbar, Total_dim, mode))\n",
    "\n",
    "                futures = [executor.submit(run_tile, *t) for t in tasks]\n",
    "\n",
    "                for f in as_completed(futures):\n",
    "                    cy, cx, col_start, col_end, out_np = f.result()\n",
    "                    out = torch.from_numpy(out_np)\n",
    "                    mac_out_columns[:, col_start:col_end] += out\n",
    "\n",
    "                output_conv_2d[:, :, ii, jj] = mac_out_columns\n",
    "\n",
    "    return output_conv_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "06533e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total inputs: 50\n",
      "torch.Size([1, 24, 24, 50])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([1, 24, 24, 2, 32])\n",
      "weights shape: torch.Size([2, 1, 32, 32])\n",
      "inputs shape: torch.Size([1, 24, 24, 2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:19<00:00,  1.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv2d_tile(x,w,Num_rows,Num_Columns,mode):\n",
    "    _N_,_HOUT_, _WOUT_,_CIN_, _kernel_size_ = x.shape\n",
    "    _COUT_, _CIN_, _kernel_size_ = w.shape\n",
    "    output_conv_2d = torch.zeros(_N_,_COUT_,_HOUT_,_WOUT_)\n",
    "\n",
    "    whole_input_size = _CIN_*_kernel_size_\n",
    "    print(f\"total inputs: {whole_input_size}\")\n",
    "    crossbar_y = math.ceil((_CIN_*_kernel_size_)/Num_rows)\n",
    "    crossbar_x = math.ceil(_COUT_/Num_Columns)\n",
    "\n",
    "    crossbar_weights = torch.zeros((crossbar_y,crossbar_x,Num_rows,Num_Columns))\n",
    "    crossbar_inputs = torch.zeros((_N_,_HOUT_,_WOUT_,crossbar_y,Num_rows))\n",
    "\n",
    "    rows_per_crossbar = math.floor(whole_input_size/crossbar_y)\n",
    "\n",
    "    flatten_x = x.reshape(*x.shape[:-2],-1)\n",
    "    print(flatten_x.shape)\n",
    "    flatten_w = w.reshape(*w.shape[:-2],-1).T\n",
    "    print(flatten_w.shape)\n",
    "    print(crossbar_inputs.shape)\n",
    "    print(f\"weights shape: {crossbar_weights.shape}\")\n",
    "    print(f\"inputs shape: {crossbar_inputs.shape}\")\n",
    "\n",
    "    columns_per_crossbar = math.floor(_COUT_/crossbar_x)\n",
    "\n",
    "    for ii in range(crossbar_y):\n",
    "        row_start_idx = ii*rows_per_crossbar\n",
    "        # if ii==crossbar_y-1:\n",
    "        #     row_end_idx = flatten_x.shape[-1]\n",
    "        # else:\n",
    "        row_end_idx = (ii+1)*rows_per_crossbar\n",
    "        # print(start_idx,end_idx)\n",
    "        crossbar_inputs[:,:,:,ii,:rows_per_crossbar] = flatten_x[:,:,:,row_start_idx:row_end_idx]\n",
    "    # for ii in range(0,whole_input_size,step=inpu)\n",
    "\n",
    "        for jj in range(crossbar_x):\n",
    "            column_start_idx = jj*columns_per_crossbar\n",
    "            # if jj==crossbar_x-1:\n",
    "            #     column_end_idx=flatten_w.shape[-1]\n",
    "            # else:\n",
    "            column_end_idx = (jj+1)*columns_per_crossbar\n",
    "            \n",
    "            crossbar_weights[ii,jj,:rows_per_crossbar,:columns_per_crossbar] = flatten_w[row_start_idx:row_end_idx,column_start_idx:column_end_idx]\n",
    "\n",
    "\n",
    "    # for n in range(_N_):\n",
    "    output_conv_2d = cim_conv_2d(crossbar_inputs,crossbar_weights,_COUT_,mode,flatten_w.shape[-1],max_workers=8)\n",
    "    # output_conv_2d = torch_conv_2d(crossbar_inputs,crossbar_weights,_COUT_,flatten_w.shape[-1])\n",
    "    return output_conv_2d\n",
    "output_conv_2d_cs=conv2d_tile(new_inputs,new_weights,Num_rows,Num_Columns,mode=\"cs\")\n",
    "output_conv_2d_cs = get_output(output_conv_2d_cs,Kh,Kw,CIN)\n",
    "torch.equal(output_conv_2d_cs,ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dfc6edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total inputs: 50\n",
      "torch.Size([1, 24, 24, 50])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([1, 24, 24, 2, 32])\n",
      "weights shape: torch.Size([2, 1, 32, 32])\n",
      "inputs shape: torch.Size([1, 24, 24, 2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:16<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "output_conv_2d_gs=conv2d_tile(new_inputs,new_weights,Num_rows,Num_Columns,mode=\"gs\")\n",
    "output_conv_2d_gs = get_output(output_conv_2d_gs,Kh,Kw,CIN)\n",
    "output_conv_2d_gs_b = binarized(output_conv_2d_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d60a7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_conv_2d_cs_b = binarized(output_conv_2d_cs) \n",
    "ref_b = binarized(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5dab35b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 24, 24])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2aca3678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
      "           -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
      "           -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
      "           -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,\n",
      "           -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,\n",
      "            0.,  0.,  0.,  0., -2., -2.,  0.,  0., -2., -2.],\n",
      "          [-2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0., -2.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0., -2.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,\n",
      "            0., -2.,  0.,  0.,  0.,  0.,  0., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0., -2., -2., -2., -2., -2., -2., -2., -2., -2.]],\n",
      "\n",
      "         [[-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
      "           -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
      "           -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
      "           -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,\n",
      "           -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0., -2.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0., -2., -2.,  0., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0., -2., -2.,  0.,  0., -2., -2.],\n",
      "          [-2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0., -2.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0., -2.,  0., -2.,  0.,  0.,  0., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,\n",
      "           -2.,  0.,  0.,  0., -2.,  0.,  0., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0., -2.,  0.,  0., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0., -2.,  0.,  0.,  0., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0., -2.,  0.,\n",
      "            0.,  0., -2., -2.,  0.,  0., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0., -2.,  0.,\n",
      "            0.,  0., -2.,  0.,  0., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0., -2.,  0.,  0.,\n",
      "            0.,  0., -2.,  0.,  0., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0.,  0., -2.,  0.,  0.,\n",
      "            0., -2.,  0.,  0., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2., -2.,  0.,  0., -2.,  0.,  0.,  0.,\n",
      "            0., -2.,  0.,  0., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2., -2.,  0.,  0., -2.,  0.,  0.,  0.,  0.,\n",
      "           -2.,  0.,  0., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2.,  0.,  0.,  0., -2.,  0.,  0.,  0., -2.,\n",
      "            0.,  0.,  0., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,\n",
      "            0., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "          [-2., -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,\n",
      "            0., -2., -2., -2., -2., -2., -2., -2., -2., -2.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,\n",
      "           -2., -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0., -2.,  0.,  0., -2.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0., -2., -2.,  0.,  0., -2.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,\n",
      "           -2.,  0., -2.,  0.,  0., -2.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,\n",
      "           -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2., -2.,  0.,\n",
      "            0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0., -2., -2.,  0., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0., -2.,  0.,  0.,  0., -2., -2., -2.,  0.,  0.,  0., -2., -2.,\n",
      "           -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0., -2., -2.,\n",
      "           -2., -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2., -2.,  0.,  0.,\n",
      "           -2., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0., -2.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0., -2.,  0.,  0.,  0., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2., -2.,  0., -2.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0., -2.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]])\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(threshold=float('inf')):\n",
    "    print(ref_b - output_conv_2d_gs_b)\n",
    "    # print(ref_b - output_conv_2d_cs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "27a9f7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 120])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_weight = model.fc1.weight.data.T\n",
    "fc_weight_b = binarized(fc_weight)\n",
    "fc_weight_b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a974fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_input = torch.randn(10,fc_weight_b.shape[0])\n",
    "fc_input_b = binarized(fc_input)\n",
    "fc_input_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f288a209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 120])\n"
     ]
    }
   ],
   "source": [
    "fc_weight_pos, fc_weight_neg = compliment(fc_weight_b) \n",
    "fc_input_pos, fc_input_neg = compliment(fc_input_b)\n",
    "\n",
    "print(fc_weight_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1d6c71ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([512, 120])\n"
     ]
    }
   ],
   "source": [
    "new_fc_weights = torch.empty((2*fc_weight_pos.shape[0],fc_weight_pos.shape[1]))\n",
    "new_fc_inputs = torch.empty((fc_input_pos.shape[0],2*fc_input_pos.shape[1]))\n",
    "\n",
    "for idx in range(fc_weight.shape[0]):\n",
    "    _pos_w_ = fc_weight_pos[idx]\n",
    "    _neg_w_ = fc_weight_neg[idx]\n",
    "    new_fc_weights[2*idx]=_pos_w_\n",
    "    new_fc_weights[2*idx+1]=_neg_w_\n",
    "\n",
    "    _pos_i_ = fc_input_pos[:,idx]\n",
    "    _neg_i_ = fc_input_neg[:,idx]\n",
    "\n",
    "    new_fc_inputs[:,2*idx] = _pos_i_\n",
    "    new_fc_inputs[:,2*idx+1] = _neg_i_\n",
    "\n",
    "print(new_fc_inputs.shape)\n",
    "print(new_fc_weights.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "61ac176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_output(I, M):\n",
    "    out = 2*I - M\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "58690f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 18.,  -2.,   8., -32., -10., -18.,   6., -28., -10., -10.,  10.,   0.,\n",
       "         -34.,  30.,  12.,  24., -22., -12.,  -4.,   8.,  12.,  -2.,   2., -32.,\n",
       "          -8.,  24., -10.,  -4.,   4.,   6., -16.,   4.,  24., -26.,   0., -18.,\n",
       "          -2.,   8.,   4.,  -8.,   6., -28., -22.,  -8., -16.,  -8., -18.,  20.,\n",
       "         -16.,  -4.,   6.,  18., -12., -16.,  -2.,  14.,  -8.,  10., -14., -10.,\n",
       "          -4.,  12., -20.,   2., -18.,   8.,   2., -32.,  -6.,   6., -12., -14.,\n",
       "          -2.,  -6.,  10.,  -6.,   4.,   4.,  -4., -16.,  14.,   4.,  10.,   0.,\n",
       "           6., -18.,  -8.,   0.,   4.,  -4., -14.,  16., -14.,  26.,  32., -14.,\n",
       "         -24.,  18.,  -2.,  14., -30., -14.,   6.,  42.,   6.,  14.,   2.,   2.,\n",
       "          -8.,  18.,   8.,   6.,  30., -18.,  22., -18., -20.,  -8.,   8.,  38.]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2d = F.linear(new_fc_inputs,new_fc_weights.T)\n",
    "out_2d = get_fc_output(out_2d,fc_input.shape[-1])\n",
    "out_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a8c43f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_fc = F.linear(fc_input_b,fc_weight_b.T)\n",
    "torch.equal(ref_fc,out_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  fc_linear(crossbar_inputs,crossbar_weights,N,mode,max_workers):\n",
    "    crossbar_y,crossbar_x,Num_rows,Num_Columns = crossbar_weights.shape\n",
    "    _N_, crossbar_y, Num_rows = crossbar_inputs.shape\n",
    "    output = torch.zeros(_N_,crossbar_x)\n",
    "    columns_per_crossbar = math.floor(N/crossbar_x)\n",
    "    print()\n",
    "    print(output.shape)\n",
    "    tasks = []\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for ii in range(crossbar_y):\n",
    "            for jj in range(crossbar_x):\n",
    "                column_start_idx = jj*columns_per_crossbar\n",
    "                column_end_idx = (jj+1)*columns_per_crossbar\n",
    "                tmp_x = crossbar_inputs[:,ii]\n",
    "                tmp_w = crossbar_weights[ii][jj]\n",
    "                checkerboard_last_cols(tmp_w,Num_Columns-columns_per_crossbar)\n",
    "                # out_matmul = torch.matmul(tmp_x,tmp_w)\n",
    "                args = (((ii,jj),tmp_x),tmp_w,Num_rows,Num_Columns,mode,False)\n",
    "                tasks.append(args)\n",
    "        futures = [executor.submit(_task, *t) for t in tasks]\n",
    "        for f in as_completed(futures):\n",
    "            (ii,jj), out_matmul = f.result()\n",
    "            print(jj)\n",
    "            column_start_idx = jj*columns_per_crossbar\n",
    "            column_end_idx = (jj+1)*columns_per_crossbar\n",
    "            out_matmul = torch.from_numpy(out_matmul)\n",
    "            print(column_start_idx,column_end_idx)\n",
    "            print(out_matmul.shape)\n",
    "            print(columns_per_crossbar)\n",
    "            output[:,column_start_idx:column_end_idx] += out_matmul[:,:columns_per_crossbar]\n",
    "\n",
    "    return output\n",
    "        \n",
    "# _ , out_matmul = _task(((ii,jj),tmp_x),tmp_w,Num_rows,Num_Columns,mode,False)\n",
    "# out_matmul = torch.from_numpy(out_matmul)\n",
    "# # print(out_matmul.shape)\n",
    "# output[:,column_start_idx:column_end_idx] += out_matmul[:,:columns_per_crossbar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0c4d0ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossbar grid 16 4\n",
      "32 30\n",
      "crossbar weigths : torch.Size([16, 4, 32, 32])\n",
      "crossbar inputs : torch.Size([1, 16, 32])\n",
      "torch.Size([1, 4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 30\n",
      "torch.Size([1, 32])\n",
      "30\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (30) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[245]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fc_linear(crossbar_inputs,crossbar_weights,N,mode,\u001b[32m8\u001b[39m)\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# output = torch.zeros(_N_,N)\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# for ii in range(crossbar_y):\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m#     # row_start_idx = ii*rows_per_crossbar\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m \n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# return output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m fc_output = \u001b[43mfc_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_fc_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnew_fc_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNum_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNum_Columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m fc_output=get_fc_output(fc_output,\u001b[32m256\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# print(fc_output)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[245]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mfc_tile\u001b[39m\u001b[34m(x, w, Num_rows, Num_Columns, mode)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcrossbar weigths : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcrossbar_weights.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcrossbar inputs : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcrossbar_inputs.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfc_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrossbar_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcrossbar_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[244]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mfc_linear\u001b[39m\u001b[34m(crossbar_inputs, crossbar_weights, N, mode, max_workers)\u001b[39m\n\u001b[32m     29\u001b[39m         \u001b[38;5;28mprint\u001b[39m(out_matmul.shape)\n\u001b[32m     30\u001b[39m         \u001b[38;5;28mprint\u001b[39m(columns_per_crossbar)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolumn_start_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcolumn_end_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_matmul\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcolumns_per_crossbar\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (4) must match the size of tensor b (30) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "def fc_tile(x,w, Num_rows,Num_Columns,mode):\n",
    "    _N_ , M = x.shape\n",
    "    M , N = w.shape\n",
    "\n",
    "    crossbar_y = math.ceil(M/Num_rows)\n",
    "    crossbar_x = math.ceil(N/Num_Columns)\n",
    "    print(\"crossbar grid\",crossbar_y,crossbar_x)\n",
    "\n",
    "    crossbar_inputs = torch.zeros((_N_,crossbar_y,Num_rows))\n",
    "    crossbar_weights = torch.zeros((crossbar_y,crossbar_x,Num_rows,Num_Columns))\n",
    "\n",
    "    rows_per_crossbar = math.floor(M/crossbar_y)\n",
    "    columns_per_crossbar = math.floor(N/crossbar_x)\n",
    "\n",
    "    print(rows_per_crossbar, columns_per_crossbar)\n",
    "\n",
    "    for ii in range(crossbar_y):\n",
    "        row_start_idx = ii*rows_per_crossbar\n",
    "        # if ii==crossbar_y-1:\n",
    "        #     row_end_idx = M\n",
    "        # else:\n",
    "        row_end_idx = (ii+1)*rows_per_crossbar\n",
    "        crossbar_inputs[:,ii,:rows_per_crossbar] = x[:,row_start_idx:row_end_idx]\n",
    "    # for ii in range(0,whole_input_size,step=inpu)\n",
    "        # print(row_start_idx,row_end_idx)\n",
    "\n",
    "        for jj in range(crossbar_x):\n",
    "            column_start_idx = jj*columns_per_crossbar\n",
    "            # if jj==crossbar_x-1:\n",
    "            #     column_end_idx=N\n",
    "            # else:\n",
    "            column_end_idx = (jj+1)*columns_per_crossbar\n",
    "            # print(column_start_idx,column_end_idx)\n",
    "            \n",
    "            crossbar_weights[ii,jj,:rows_per_crossbar,:columns_per_crossbar] = w[row_start_idx:row_end_idx,column_start_idx:column_end_idx]\n",
    "        \n",
    "    print(f\"crossbar weigths : {crossbar_weights.shape}\")\n",
    "    print(f\"crossbar inputs : {crossbar_inputs.shape}\")\n",
    "    return fc_linear(crossbar_inputs,crossbar_weights,N,mode,8)\n",
    "    # output = torch.zeros(_N_,N)\n",
    "    # for ii in range(crossbar_y):\n",
    "    #     # row_start_idx = ii*rows_per_crossbar\n",
    "    #     # row_end_idx = (ii+1)*rows_per_crossbar\n",
    "    #     for jj in range(crossbar_x):\n",
    "    #         column_start_idx = jj*columns_per_crossbar\n",
    "    #         # if jj==crossbar_x-1:\n",
    "    #         #     column_end_idx=N\n",
    "    #         # else:\n",
    "    #         column_end_idx = (jj+1)*columns_per_crossbar\n",
    "    #         tmp_x = crossbar_inputs[:,ii]\n",
    "    #         tmp_w = crossbar_weights[ii][jj]\n",
    "    #         checkerboard_last_cols(tmp_w,Num_Columns-columns_per_crossbar)\n",
    "    #         _ , out_matmul = _task(((ii,jj),tmp_x),tmp_w,Num_rows,Num_Columns,mode,False)\n",
    "    #         out_matmul = torch.from_numpy(out_matmul)\n",
    "    #         output[:,column_start_idx:column_end_idx] += out_matmul[:,:columns_per_crossbar]\n",
    "\n",
    "    # return output\n",
    "\n",
    "\n",
    "fc_output = fc_tile(new_fc_inputs,new_fc_weights,Num_rows,Num_Columns,mode=\"gs\")\n",
    "fc_output=get_fc_output(fc_output,256)\n",
    "# print(fc_output)\n",
    "torch.equal(fc_output,ref_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4f109369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 18.,  -2.,   8., -32., -10., -18.,   6., -28., -10., -10.,  10.,   0.,\n",
       "         -34.,  30.,  12.,  24., -22., -12.,  -4.,   8.,  12.,  -2.,   2., -32.,\n",
       "          -8.,  24., -10.,  -4.,   4.,   6., -16.,   4.,  24., -26.,   0., -18.,\n",
       "          -2.,   8.,   4.,  -8.,   6., -28., -22.,  -8., -16.,  -8., -18.,  20.,\n",
       "         -16.,  -4.,   6.,  18., -12., -16.,  -2.,  14.,  -8.,  10., -14., -10.,\n",
       "          -4.,  12., -20.,   2., -18.,   8.,   2., -32.,  -6.,   6., -12., -14.,\n",
       "          -2.,  -6.,  10.,  -6.,   4.,   4.,  -4., -16.,  14.,   4.,  10.,   0.,\n",
       "           6., -18.,  -8.,   0.,   4.,  -4., -14.,  16., -14.,  26.,  32., -14.,\n",
       "         -24.,  18.,  -2.,  14., -30., -14.,   6.,  42.,   6.,  14.,   2.,   2.,\n",
       "          -8.,  18.,   8.,   6.,  30., -18.,  22., -18., -20.,  -8.,   8.,  38.]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f1faafa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 32.,  30.,  32.,  24.,  26.,  16.,  14.,   4.,   4.,   2.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  -2.,   0.,  -2.,   0.,\n",
       "           0.,  -2.,  -2.,  -2.,  -4.,  -6.,  32.,  32.,  32.,  30.,  24.,  26.,\n",
       "          16.,  12.,   4.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,  -2.,   0.,  -2.,   0.,  -6.,  -8.,  -4.,  -2.,   0.,  -4.,\n",
       "          32.,  32.,  32.,  32.,  26.,  30.,  14.,  14.,   2.,   4.,   2.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  -2.,  -2.,  -2.,\n",
       "          -2.,  -2.,  -4.,  -6.,  -4.,  -4.,  32.,  30.,  28.,  32.,  32.,  18.,\n",
       "          18.,   8.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,  -2.,  -8.,  -4.,  -6.,  -4.,  -2.,  -6.,  -6., -12.]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_output - ref_fc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
