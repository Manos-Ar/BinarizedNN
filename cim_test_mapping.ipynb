{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dc865033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from models.binarized_modules import binarized\n",
    "# from binarized_modules import  BinarizeLinear,BinarizeConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "86bde069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/earapidis/Fast-Crossbar-Sim/python')\n",
    "from crossbar import VectorSim, ParallelSim, _task\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8b3bde3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/earapidis/BinarizedNN'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "236bd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False\n",
    "# cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "62f8a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e85599be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "51fbfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a26c3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2d875105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mnist_bnn import Net\n",
    "from models.lenet_5 import BinarizedLeNet5_BN as Net\n",
    "\n",
    "model = Net()\n",
    "if cuda:\n",
    "    torch.cuda.set_device(0)\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3117c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = os.path.join(models_path,f\"epoch_7.pth\")\n",
    "model_idx = 1\n",
    "models_path = os.path.abspath(f\"/home/earapidis/BinarizedNN/saved_models/lenet_5/model_{model_idx}\")\n",
    "model_path = os.path.join(models_path,f\"epoch_15.pth\")\n",
    "# model_path = os.path.join(models_path,f\"best.pth\")\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "if cuda:\n",
    "    torch.cuda.set_device(0)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "227bd705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinarizedLeNet5_BN(\n",
       "  (conv1): BinarizeConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh1): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): BinarizeConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): BinarizeLinear(in_features=256, out_features=120, bias=True)\n",
       "  (bn_fc1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh3): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (fc2): BinarizeLinear(in_features=120, out_features=84, bias=True)\n",
       "  (bn_fc2): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh4): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (fc3): BinarizeLinear(in_features=84, out_features=10, bias=True)\n",
       "  (bn_fc3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fdc484eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.conv2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1c952b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 5, 5])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv2.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e6eb9a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 5, 5])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters = model.conv2.weight.data\n",
    "filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "38c44fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUT = 50\n",
    "CIN = 6\n",
    "Kh = 5\n",
    "Kw = 5\n",
    "filters = torch.randn(COUT,CIN,Kh,Kw)\n",
    "filters = binarized(filters)\n",
    "\n",
    "# COUT, CIN, Kh, Kw = filters.shape\n",
    "\n",
    "Hi = 24\n",
    "Wi = 24\n",
    "padding = 0 \n",
    "N = 1\n",
    "Num_rows = 32\n",
    "Num_Columns = 32                    \n",
    "Hout = Hi + 2*padding - Kh + 1\n",
    "Wout = Wi + 2*padding - Kw + 1\n",
    "\n",
    "\n",
    "# filters = torch.randn(COUT, CIN, Kh, Kw)\n",
    "\n",
    "inputs = torch.randn(N, CIN, Hi, Wi)\n",
    "inputs = binarized(inputs)\n",
    "filters_b = binarized(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "47842069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 6, 5, 5])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "19407a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 1, 0, 1, 0, 1, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def checkerboard_last_cols(arr: torch.Tensor, C: int) -> None:\n",
    "    \"\"\"\n",
    "    Overwrite the last C columns of `arr` in-place with a checkerboard pattern of 0s and 1s.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : torch.Tensor\n",
    "        Input 2D tensor of shape (n, m).\n",
    "    C : int\n",
    "        Number of columns at the right edge to turn into a checkerboard.\n",
    "    \"\"\"\n",
    "    n, m = arr.shape\n",
    "    if C > m:\n",
    "        raise ValueError(\"C cannot be larger than the number of columns m.\")\n",
    "    \n",
    "    # Create row and column indices\n",
    "    rows = torch.arange(n).view(-1, 1)                # shape: (n, 1)\n",
    "    cols = torch.arange(m - C, m).view(1, -1)         # shape: (1, C)\n",
    "\n",
    "    # Generate checkerboard pattern\n",
    "    pattern = (rows + cols) % 2\n",
    "\n",
    "    # Apply the pattern to the last C columns in-place\n",
    "    arr[:, -C:] = pattern\n",
    "\n",
    "# Example\n",
    "A = torch.ones((6, 8), dtype=torch.int)\n",
    "checkerboard_last_cols(A, C=5)\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9b88f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compliment(x):\n",
    "    x = x.clone()\n",
    "    neg = -1*x\n",
    "    pos = x\n",
    "\n",
    "    pos[pos==-1] = 0\n",
    "    neg[neg==-1] = 0\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4db5e20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 6, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "pos_inputs, neg_inputs = compliment(inputs)\n",
    "pos_filters, neg_filters = compliment(filters_b)\n",
    "\n",
    "print(pos_filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4357b472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 6, 50])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = torch.empty((COUT,CIN,2*(Kh*Kw)))\n",
    "\n",
    "pos = pos_filters.reshape(pos_filters.shape[0],pos_filters.shape[1],-1)\n",
    "neg = neg_filters.reshape(neg_filters.shape[0],neg_filters.shape[1],-1)\n",
    "kernel_size = Kh*Kw\n",
    "\n",
    "for i in range(kernel_size):\n",
    "\n",
    "    new_weights[:,:,2*i] = pos[:,:,i]\n",
    "    new_weights[:,:,2*i+1] = neg[:,:,i]\n",
    "new_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "24e5748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inputs = torch.empty((N,Hout,Wout,CIN,2*kernel_size))\n",
    "for ii in range(Hout):\n",
    "    for jj in range(Wout):\n",
    "        _pos_ = pos_inputs[:,:,ii:ii+Kh,jj:jj+Kw]\n",
    "        _neg_ = neg_inputs[:,:,ii:ii+Kh,jj:jj+Kw]\n",
    "        _pos_ = _pos_.reshape(_pos_.shape[0],_pos_.shape[1],-1)\n",
    "        _neg_ = _neg_.reshape(_neg_.shape[0],_neg_.shape[1],-1)\n",
    "        one_pixel = torch.empty(_pos_.shape[0],_pos_.shape[1],2*kernel_size)\n",
    "        for z in range(kernel_size):\n",
    "            one_pixel[:,:,2*z]=_pos_[:,:,z]\n",
    "            one_pixel[:,:,2*z+1]=_neg_[:,:,z]\n",
    "        new_inputs[:,ii,jj,:,:] = one_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "13463043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 20, 6, 50])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f30a235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(I,Kh, Kw, CIN):\n",
    "    out = 2*I - Kh*Kw*CIN\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2468f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = nn.functional.conv2d(inputs, filters_b, padding=0)\n",
    "# ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b517ce08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2d = torch.empty((N,COUT,Hout,Wout))\n",
    "\n",
    "for ii in range(Hout):\n",
    "    for jj in range(Wout):\n",
    "        one_pixel = new_inputs[:,ii,jj,:,:]\n",
    "        # print(one_pixel.shape)\n",
    "        out_1d = F.conv1d(one_pixel,new_weights)\n",
    "        out_1d = out_1d.squeeze(-1)\n",
    "        # print(out_1d.shape)\n",
    "        out_2d[:,:,ii,jj] = out_1d\n",
    "out_2d = get_output(out_2d,Kh,Kw,CIN)\n",
    "torch.equal(out_2d,ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "829e0764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 6, 50])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2b6f4211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function math.ceil(x, /)>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7ee6537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_conv_2d(crossbar_inputs,crossbar_weights,_COUT_,Total_dim):\n",
    "    _N_,_HOUT_,_WOUT_,crossbar_y,Num_rows = crossbar_inputs.shape\n",
    "    _,crossbar_x,_,Num_Columns = crossbar_weights.shape\n",
    "    output_conv_2d = torch.zeros(_N_,_COUT_,_HOUT_,_WOUT_)\n",
    "\n",
    "    columns_per_crossbar = math.floor(_COUT_/crossbar_x)\n",
    "\n",
    "    for ii in range(_HOUT_):\n",
    "        for jj in range(_WOUT_):\n",
    "            mac_out_columns = torch.zeros((_N_,_COUT_))\n",
    "            for cy in range(crossbar_y):\n",
    "                for cx in range(crossbar_x):\n",
    "                    tmp_x=crossbar_inputs[:,ii,jj,cy,:]\n",
    "                    tmp_w=crossbar_weights[cy,cx,:,:]\n",
    "                    checkerboard_last_cols(tmp_w,Num_Columns-columns_per_crossbar)\n",
    "                    # tmp_w=crossbar_weights\n",
    "                    # print(tmp_x.shape)\n",
    "                    # print(tmp_w.shape)\n",
    "                    # _out_ = torch.matmul(tmp_w,tmp_x)\n",
    "                    _out_ = torch.matmul(tmp_x,tmp_w)\n",
    "\n",
    "                    column_start_idx = cx*columns_per_crossbar\n",
    "                    if cx==crossbar_x-1:\n",
    "                        column_end_idx=Total_dim\n",
    "                    else:\n",
    "                        column_end_idx = (cx+1)*columns_per_crossbar\n",
    "                    \n",
    "                    mac_out_columns[:,column_start_idx:column_end_idx] += _out_[:,:columns_per_crossbar]\n",
    "            output_conv_2d[:,:,ii,jj]=mac_out_columns\n",
    "    return output_conv_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "06533e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total inputs: 300\n",
      "torch.Size([1, 20, 20, 300])\n",
      "torch.Size([300, 50])\n",
      "torch.Size([1, 20, 20, 10, 32])\n",
      "weights shape: torch.Size([10, 2, 32, 32])\n",
      "inputs shape: torch.Size([1, 20, 20, 10, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv2d_tile(x,w,Num_rows,Num_Columns):\n",
    "    _N_,_HOUT_, _WOUT_,_CIN_, _kernel_size_ = x.shape\n",
    "    _COUT_, _CIN_, _kernel_size_ = w.shape\n",
    "    output_conv_2d = torch.zeros(_N_,_COUT_,_HOUT_,_WOUT_)\n",
    "\n",
    "    whole_input_size = _CIN_*_kernel_size_\n",
    "    print(f\"total inputs: {whole_input_size}\")\n",
    "    crossbar_y = math.ceil((_CIN_*_kernel_size_)/Num_rows)\n",
    "    crossbar_x = math.ceil(_COUT_/Num_Columns)\n",
    "\n",
    "    crossbar_weights = torch.zeros((crossbar_y,crossbar_x,Num_rows,Num_Columns))\n",
    "    crossbar_inputs = torch.zeros((_N_,_HOUT_,_WOUT_,crossbar_y,Num_rows))\n",
    "\n",
    "    rows_per_crossbar = math.floor(whole_input_size/crossbar_y)\n",
    "\n",
    "    flatten_x = x.reshape(*x.shape[:-2],-1)\n",
    "    print(flatten_x.shape)\n",
    "    flatten_w = w.reshape(*w.shape[:-2],-1).T\n",
    "    print(flatten_w.shape)\n",
    "    print(crossbar_inputs.shape)\n",
    "    print(f\"weights shape: {crossbar_weights.shape}\")\n",
    "    print(f\"inputs shape: {crossbar_inputs.shape}\")\n",
    "\n",
    "    columns_per_crossbar = math.floor(_COUT_/crossbar_x)\n",
    "\n",
    "    for ii in range(crossbar_y):\n",
    "        row_start_idx = ii*rows_per_crossbar\n",
    "        if ii==crossbar_y-1:\n",
    "            row_end_idx = flatten_x.shape[-1]\n",
    "        else:\n",
    "            row_end_idx = (ii+1)*rows_per_crossbar\n",
    "        # print(start_idx,end_idx)\n",
    "        crossbar_inputs[:,:,:,ii,:rows_per_crossbar] = flatten_x[:,:,:,row_start_idx:row_end_idx]\n",
    "    # for ii in range(0,whole_input_size,step=inpu)\n",
    "\n",
    "        for jj in range(crossbar_x):\n",
    "            column_start_idx = jj*columns_per_crossbar\n",
    "            if jj==crossbar_x-1:\n",
    "                column_end_idx=flatten_w.shape[-1]\n",
    "            else:\n",
    "                column_end_idx = (jj+1)*columns_per_crossbar\n",
    "            \n",
    "            crossbar_weights[ii,jj,:rows_per_crossbar,:columns_per_crossbar] = flatten_w[row_start_idx:row_end_idx,column_start_idx:column_end_idx]\n",
    "\n",
    "\n",
    "    # for n in range(_N_):\n",
    "    output_conv_2d = torch_conv_2d(crossbar_inputs,crossbar_weights,_COUT_,flatten_w.shape[-1])\n",
    "    return output_conv_2d\n",
    "output_conv_2d=conv2d_tile(new_inputs,new_weights,Num_rows,Num_Columns)\n",
    "output_conv_2d = get_output(output_conv_2d,Kh,Kw,CIN)\n",
    "torch.equal(output_conv_2d,ref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
