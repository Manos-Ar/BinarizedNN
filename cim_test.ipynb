{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "dc865033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from models.binarized_modules import binarized\n",
    "# from binarized_modules import  BinarizeLinear,BinarizeConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "86bde069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/earapidis/Fast-Crossbar-Sim/python')\n",
    "from crossbar import VectorSim, ParallelSim, _task\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "236bd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False\n",
    "# cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "62f8a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "e85599be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "51fbfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "a26c3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "2d875105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mnist_bnn import Net\n",
    "from models.lenet_5 import BinarizedLeNet5_BN as Net\n",
    "\n",
    "model = Net()\n",
    "if cuda:\n",
    "    torch.cuda.set_device(0)\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "3117c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = os.path.join(models_path,f\"epoch_7.pth\")\n",
    "model_idx = 1\n",
    "models_path = os.path.abspath(f\"/home/earapidis/BinarizedNN/saved_models/lenet_5/model_{model_idx}\")\n",
    "model_path = os.path.join(models_path,f\"epoch_15.pth\")\n",
    "# model_path = os.path.join(models_path,f\"best.pth\")\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "if cuda:\n",
    "    torch.cuda.set_device(0)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "id": "227bd705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinarizedLeNet5_BN(\n",
       "  (conv1): BinarizeConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh1): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): BinarizeConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): BinarizeLinear(in_features=256, out_features=120, bias=True)\n",
       "  (bn_fc1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh3): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (fc2): BinarizeLinear(in_features=120, out_features=84, bias=True)\n",
       "  (bn_fc2): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (htanh4): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (fc3): BinarizeLinear(in_features=84, out_features=10, bias=True)\n",
       "  (bn_fc3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "id": "fdc484eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.conv2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "id": "38c44fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIN = 1\n",
    "COUT  = 6\n",
    "Hi = 28\n",
    "Wi = 28\n",
    "Kh = 5\n",
    "Kw = 5\n",
    "padding = 0 \n",
    "N = 1\n",
    "Num_rows = 32\n",
    "Num_Columns = 32                    \n",
    "\n",
    "filters = model.conv1.weight.data\n",
    "\n",
    "# filters = torch.randn(COUT, CIN, Kh, Kw)\n",
    "\n",
    "inputs = torch.randn(N, CIN, Hi, Wi)\n",
    "inputs = binarized(inputs)\n",
    "filters_b = binarized(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "id": "47842069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 5, 5])"
      ]
     },
     "execution_count": 1057,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "8c5f5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def conv2d_loops(x, w, padding=0):\n",
    "#     N, Cin, H, W     = x.shape\n",
    "#     Cout, _, Kh, Kw  = w.shape\n",
    "#     Hout = H + 2*padding - Kh + 1\n",
    "#     Wout = W + 2*padding - Kw + 1\n",
    "\n",
    "#     # Zero-pad input\n",
    "#     x_p = torch.zeros((N, Cin, H + 2*padding, W + 2*padding))\n",
    "#     x_p[:, :, padding:padding+H, padding:padding+W] = x\n",
    "\n",
    "#     y = torch.zeros((N, Cout, Hout, Wout))\n",
    "#     for n in range(N):\n",
    "#         for co in range(Cout):\n",
    "#             for i in range(Hout):\n",
    "#                 for j in range(Wout):\n",
    "#                     acc = 0.0\n",
    "#                     for ci in range(Cin):\n",
    "#                         acc += torch.sum(x_p[n, ci, i:i+Kh, j:j+Kw] * w[co, ci])\n",
    "#                     y[n, co, i, j] = acc\n",
    "#     return y\n",
    "\n",
    "# ref = F.conv2d(inputs, filters, padding=padding)\n",
    "# out_loops  = conv2d_loops(inputs, filters, padding)\n",
    "# print(\"Reference shape:\", ref.shape)\n",
    "# print(\"Max abs diff (loops):\",  (ref - out_loops).abs().max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "id": "9788d6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1059,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = F.conv2d(inputs, filters_b, padding=padding)\n",
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "id": "19407a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 1 0 1]\n",
      " [1 1 1 0 1 0 1 0]\n",
      " [1 1 1 1 0 1 0 1]\n",
      " [1 1 1 0 1 0 1 0]\n",
      " [1 1 1 1 0 1 0 1]\n",
      " [1 1 1 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def checkerboard_last_cols(arr: np.ndarray, C: int) -> None:\n",
    "    \"\"\"\n",
    "    Overwrite the last C columns of `arr` in-place with a checkerboard pattern of 0s and 1s.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Input array of shape (n, m).\n",
    "    C : int\n",
    "        Number of columns at the right edge to turn into a checkerboard.\n",
    "    \"\"\"\n",
    "    n, m = arr.shape\n",
    "    if C > m:\n",
    "        raise ValueError(\"C cannot be larger than the number of columns m.\")\n",
    "    \n",
    "    # row indices: shape (n, 1)\n",
    "    rows = np.arange(n)[:, None]\n",
    "    # column indices of the last C columns: shape (C,)\n",
    "    cols = np.arange(m - C, m)\n",
    "    \n",
    "    # Checkerboard pattern: (row + col) mod 2\n",
    "    # This produces 0/1 alternating in both directions.\n",
    "    pattern = (rows + cols) % 2\n",
    "    \n",
    "    # Write it back into the last C columns\n",
    "    arr[:, -C:] = pattern\n",
    "\n",
    "# Example\n",
    "A = np.ones((6, 8), dtype=int)\n",
    "checkerboard_last_cols(A, C=5)\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "id": "dd68ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def checkerboard_last_cols(arr: np.ndarray, C: int) -> None:\n",
    "#     \"\"\"\n",
    "#     Overwrite the last C columns of `arr` in-place with a checkerboard pattern of 0s and 1s.\n",
    "#     \"\"\"\n",
    "#     n, m = arr.shape\n",
    "#     if C > m:\n",
    "#         raise ValueError(\"C cannot be larger than the number of columns m.\")\n",
    "#     rows = np.arange(n)[:, None]\n",
    "#     cols = np.arange(m - C, m)\n",
    "#     pattern = (rows + cols) % 2\n",
    "#     arr[:, -C:] = pattern\n",
    "\n",
    "# def _process_one_pixel(args):\n",
    "#     \"\"\"\n",
    "#     Compute the conv2d_tiles result for a single (n,i,j) position.\n",
    "#     Returns (n, i, j, output_vector).\n",
    "#     \"\"\"\n",
    "#     (n, i, j,\n",
    "#      input_vec,\n",
    "#      crossbar_weights,\n",
    "#      Cout,\n",
    "#      num_tiles_columns,\n",
    "#      Num_rows,\n",
    "#      Num_Columns,\n",
    "#      mode,\n",
    "#      checkboard) = args\n",
    "\n",
    "#     inp = input_vec[n, i, j, :, :]  # shape (num_tiles_rows, Num_rows)\n",
    "#     full_out = np.zeros(num_tiles_columns * Num_Columns, dtype=float)\n",
    "\n",
    "#     for col_idx in range(num_tiles_columns):\n",
    "#         weight_tiles = crossbar_weights[:, col_idx, :, :]  # (num_tiles_rows, Num_rows, Num_Columns)\n",
    "#         accum = np.zeros((weight_tiles.shape[0], Num_Columns), dtype=float)\n",
    "\n",
    "#         for t_idx, vec in enumerate(inp):\n",
    "#             W = weight_tiles[t_idx]\n",
    "#             if checkboard and col_idx == num_tiles_columns - 1:\n",
    "#                 checkerboard_last_cols(W, Num_Columns - Cout)\n",
    "#             _, out_vec = _task((t_idx, vec), W, Num_rows, Num_Columns, mode, False)\n",
    "#             accum[t_idx, :] = out_vec\n",
    "\n",
    "#         summed = accum.sum(axis=0)\n",
    "#         start = col_idx * Num_Columns\n",
    "#         full_out[start:start + Num_Columns] = summed\n",
    "\n",
    "#     return n, i, j, full_out[:Cout]\n",
    "\n",
    "# def conv2d_tiles(x, w, Num_rows, Num_Columns, padding=0, mode=\"gs\", checkboard=False):\n",
    "#     N, Cin, H, W     = x.shape\n",
    "#     Cout, _, Kh, Kw  = w.shape\n",
    "#     Hout = H + 2*padding - Kh + 1\n",
    "#     Wout = W + 2*padding - Kw + 1\n",
    "\n",
    "#     # Zero-pad input\n",
    "#     x_p = torch.zeros((N, Cin, H + 2*padding, W + 2*padding), dtype=x.dtype, device=x.device)\n",
    "#     x_p[:, :, padding:padding+H, padding:padding+W] = x\n",
    "\n",
    "#     # Build crossbar_weights\n",
    "#     kernel_size = Kh * Kw\n",
    "#     cin_per_cross = Num_rows // kernel_size\n",
    "#     num_tiles_rows = int(np.ceil((kernel_size * Cin) / (cin_per_cross * kernel_size)))\n",
    "#     num_tiles_columns = int(np.ceil(Cout / Num_Columns))\n",
    "\n",
    "#     crossbar_weights = np.zeros((num_tiles_rows, num_tiles_columns, Num_rows, Num_Columns), dtype=float)\n",
    "#     for co in range(Cout):\n",
    "#         tile_j = co // Num_Columns\n",
    "#         col_idx = co % Num_Columns\n",
    "#         for ci in range(Cin):\n",
    "#             tile_i = ci // cin_per_cross\n",
    "#             id_mod = ci % cin_per_cross\n",
    "#             start = id_mod * kernel_size\n",
    "#             end   = start + kernel_size\n",
    "#             flat_w = w[co, ci].view(-1).cpu().numpy()\n",
    "#             crossbar_weights[tile_i, tile_j, start:end, col_idx] = flat_w\n",
    "\n",
    "#     # Build input_vec\n",
    "#     input_vec = np.zeros((N, Hout, Wout, num_tiles_rows, Num_rows), dtype=float)\n",
    "#     for n in range(N):\n",
    "#         for ci in range(Cin):\n",
    "#             tile_i = ci // cin_per_cross\n",
    "#             id_mod = ci % cin_per_cross\n",
    "#             start = id_mod * kernel_size\n",
    "#             end   = start + kernel_size\n",
    "#             for i in range(Hout):\n",
    "#                 for j in range(Wout):\n",
    "#                     patch = x_p[n, ci, i:i+Kh, j:j+Kw].contiguous().view(-1).cpu().numpy()\n",
    "#                     input_vec[n, i, j, tile_i, start:end] = patch\n",
    "\n",
    "#     # Allocate output\n",
    "#     output = np.zeros((N, Cout, Hout, Wout), dtype=float)\n",
    "\n",
    "#     # Parallelize over (i,j) for each batch n\n",
    "#     for n in range(N):\n",
    "#         tasks = [\n",
    "#             (\n",
    "#                 n, i, j,\n",
    "#                 input_vec,\n",
    "#                 crossbar_weights,\n",
    "#                 Cout,\n",
    "#                 num_tiles_columns,\n",
    "#                 Num_rows,\n",
    "#                 Num_Columns,\n",
    "#                 mode,\n",
    "#                 checkboard\n",
    "#             )\n",
    "#             for i in range(Hout) for j in range(Wout)\n",
    "#         ]\n",
    "\n",
    "#         with ProcessPoolExecutor() as executor:\n",
    "#             for n_ret, i_ret, j_ret, vec_out in executor.map(_process_one_pixel, tasks):\n",
    "#                 output[n_ret, :, i_ret, j_ret] = vec_out\n",
    "\n",
    "#     return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "ae6a760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def checkerboard_last_cols(arr: np.ndarray, C: int) -> None:\n",
    "    \"\"\"\n",
    "    Overwrite the last C columns of `arr` in-place with a checkerboard pattern of 0s and 1s.\n",
    "    \"\"\"\n",
    "    n, m = arr.shape\n",
    "    if C > m:\n",
    "        raise ValueError(\"C cannot be larger than the number of columns m.\")\n",
    "    rows = np.arange(n)[:, None]\n",
    "    cols = np.arange(m - C, m)\n",
    "    pattern = (rows + cols) % 2\n",
    "    arr[:, -C:] = pattern\n",
    "\n",
    "\n",
    "def _process_one_pixel(args):\n",
    "    \"\"\"\n",
    "    Compute the conv2d_tiles result for a single (n,i,j) position.\n",
    "    Returns (n, i, j, output_vector).\n",
    "    \"\"\"\n",
    "    (n, i, j,\n",
    "     input_vec,\n",
    "     crossbar_weights,\n",
    "     Cout,\n",
    "     num_tiles_columns,\n",
    "     Num_rows,\n",
    "     Num_Columns,\n",
    "     mode,\n",
    "     checkboard) = args\n",
    "\n",
    "    inp = input_vec[n, i, j, :, :]  # (num_tiles_rows, Num_rows)\n",
    "    full_out = np.zeros(num_tiles_columns * Num_Columns, dtype=float)\n",
    "\n",
    "    for col_idx in range(num_tiles_columns):\n",
    "        weight_tiles = crossbar_weights[:, col_idx, :, :]  # (num_tiles_rows, Num_rows, Num_Columns)\n",
    "        accum = np.zeros((weight_tiles.shape[0], Num_Columns), dtype=float)\n",
    "\n",
    "        for t_idx, vec in enumerate(inp):\n",
    "            W = weight_tiles[t_idx]\n",
    "            if checkboard and col_idx == num_tiles_columns - 1:\n",
    "                checkerboard_last_cols(W, Num_Columns - Cout)\n",
    "            _, out_vec = _task((t_idx, vec), W, Num_rows, Num_Columns, mode, False)\n",
    "            accum[t_idx, :] = out_vec\n",
    "\n",
    "        summed = accum.sum(axis=0)\n",
    "        start = col_idx * Num_Columns\n",
    "        full_out[start:start + Num_Columns] = summed\n",
    "\n",
    "    return n, i, j, full_out[:Cout]\n",
    "\n",
    "\n",
    "def conv2d_tiles(x, w, Num_rows, Num_Columns, padding=0, mode=\"gs\", checkboard=False,workers=8):\n",
    "    N, Cin, H, W     = x.shape\n",
    "    Cout, _, Kh, Kw  = w.shape\n",
    "    # print(\"Input shape:\", x.shape)\n",
    "    # print(\"weight shape:\", w.shape)\n",
    "    # print(H, W, Kh, Kw)\n",
    "    # print(Cout, Cin, N)\n",
    "    # print(padding)\n",
    "    Hout = H + 2*padding - Kh + 1\n",
    "    Wout = W + 2*padding - Kw + 1\n",
    "\n",
    "    # Zero-pad input\n",
    "    x_p = torch.zeros((N, Cin, H + 2*padding, W + 2*padding), dtype=x.dtype, device=x.device)\n",
    "    x_p[:, :, padding:padding+H, padding:padding+W] = x\n",
    "\n",
    "    # Build crossbar_weights\n",
    "    kernel_size = Kh * Kw\n",
    "    cin_per_cross = Num_rows // kernel_size\n",
    "    num_tiles_rows = int(np.ceil((kernel_size * Cin) / (cin_per_cross * kernel_size)))\n",
    "    num_tiles_columns = int(np.ceil(Cout / Num_Columns))\n",
    "\n",
    "    crossbar_weights = np.zeros((num_tiles_rows, num_tiles_columns, Num_rows, Num_Columns), dtype=float)\n",
    "    for co in range(Cout):\n",
    "        tile_j = co // Num_Columns\n",
    "        col_idx = co % Num_Columns\n",
    "        for ci in range(Cin):\n",
    "            tile_i = ci // cin_per_cross\n",
    "            id_mod = ci % cin_per_cross\n",
    "            start = id_mod * kernel_size\n",
    "            end   = start + kernel_size\n",
    "            # flat_w = w[co, ci].view(-1).detach()\n",
    "            flat_w = w[co, ci].view(-1).detach().numpy()\n",
    "            crossbar_weights[tile_i, tile_j, start:end, col_idx] = flat_w\n",
    "\n",
    "    # Build input_vec\n",
    "    input_vec = np.zeros((N, Hout, Wout, num_tiles_rows, Num_rows), dtype=float)\n",
    "    for n in range(N):\n",
    "        for ci in range(Cin):\n",
    "            tile_i = ci // cin_per_cross\n",
    "            id_mod = ci % cin_per_cross\n",
    "            start = id_mod * kernel_size\n",
    "            end   = start + kernel_size\n",
    "            for i in range(Hout):\n",
    "                for j in range(Wout):\n",
    "                    # patch = x_p[n, ci, i:i+Kh, j:j+Kw].contiguous().view(-1).detach()\n",
    "                    patch = x_p[n, ci, i:i+Kh, j:j+Kw].contiguous().view(-1).detach().numpy()\n",
    "                    input_vec[n, i, j, tile_i, start:end] = patch\n",
    "\n",
    "    # Allocate output\n",
    "    output = np.zeros((N, Cout, Hout, Wout), dtype=float)\n",
    "\n",
    "    # Parallelize over (i,j) for each batch n using futures and as_completed\n",
    "    for n in range(N):\n",
    "        args_list = [\n",
    "            (\n",
    "                n, i, j,\n",
    "                input_vec,\n",
    "                crossbar_weights,\n",
    "                Cout,\n",
    "                num_tiles_columns,\n",
    "                Num_rows,\n",
    "                Num_Columns,\n",
    "                mode,\n",
    "                checkboard\n",
    "            )\n",
    "            for i in range(Hout) for j in range(Wout)\n",
    "        ]\n",
    "        disable_loggin = True\n",
    "        with ProcessPoolExecutor(max_workers=workers) as executor:\n",
    "            futures = [executor.submit(_process_one_pixel, args) for args in args_list]\n",
    "            for future in tqdm(as_completed(futures), total=len(futures),disable=disable_loggin):\n",
    "                n_ret, i_ret, j_ret, vec_out = future.result()\n",
    "                output[n_ret, :, i_ret, j_ret] = vec_out\n",
    "    output = torch.from_numpy(output)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "id": "07b817d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conv2d_tiles(x, w, Num_rows, Num_Columns, padding=0,mode=\"gs\",checkboard=False):\n",
    "#     N, Cin, H, W     = x.shape\n",
    "#     Cout, _, Kh, Kw  = w.shape\n",
    "#     Hout = H + 2*padding - Kh + 1\n",
    "#     Wout = W + 2*padding - Kw + 1\n",
    "\n",
    "\n",
    "\n",
    "#     # Zero-pad input\n",
    "#     x_p = torch.zeros((N, Cin, H + 2*padding, W + 2*padding))\n",
    "#     x_p[:, :, padding:padding+H, padding:padding+W] = x\n",
    "\n",
    "#     kernel_size = Kh * Kw\n",
    "#     cin_per_cross = Num_rows // kernel_size \n",
    "#     num_tiles_rows = int(np.ceil((Kw * Kh*Cin)/ (cin_per_cross*kernel_size)))\n",
    "#     num_tiles_columns = int(np.ceil(Cout / Num_Columns))\n",
    "\n",
    "#     crossbar_weights = np.zeros((num_tiles_rows,num_tiles_columns,Num_rows, Num_Columns))\n",
    "#     tile_i_idx = 0\n",
    "#     tile_j_idx = 0\n",
    "#     # print(num_tiles_rows)\n",
    "#     # print(crossbar_weights.shape)\n",
    "#     for co in range(Cout):\n",
    "#         tile_j_idx = co // Num_Columns\n",
    "#         for ci in range(Cin):\n",
    "#             id = (ci%cin_per_cross)\n",
    "#             tile_row_start = id*kernel_size\n",
    "#             tile_row_end = (id+1)*kernel_size\n",
    "#             tile_i_idx = ci // cin_per_cross\n",
    "#             flat_w = w[co, ci].view(-1).numpy()\n",
    "#             # print(f\"co: {co}, ci: {ci}, tile_j_idx: {tile_j_idx}, tile_i_idx: {tile_i_idx}, tile_row_start: {tile_row_start}, tile_row_end: {tile_row_end}\")\n",
    "#             column = co % Num_Columns\n",
    "#             crossbar_weights[tile_i_idx, tile_j_idx, tile_row_start:tile_row_end, column] = flat_w\n",
    "    \n",
    "#     input_vec = np.zeros((N,Hout,Wout,num_tiles_rows,Num_rows))\n",
    "#     # print(input_vec.shape)\n",
    "#     for n in range(N):\n",
    "#         for ci in range(Cin):\n",
    "#             for i in range(Hout):\n",
    "#                 for j in range(Wout):\n",
    "#                     id = (ci%cin_per_cross)\n",
    "#                     tile_row_start = id*kernel_size\n",
    "#                     tile_row_end = (id+1)*kernel_size\n",
    "#                     tile_i_idx = ci // cin_per_cross\n",
    "#                     flat_input = torch.flatten(x_p[n, ci, i:i+Kh, j:j+Kw]).numpy()\n",
    "#                     # print(flat_input.shape)\n",
    "#                     input_vec[n,i,j,tile_i_idx, tile_row_start:tile_row_end] = flat_input\n",
    "\n",
    "#     output = np.zeros((N,Cout,Hout,Wout))\n",
    "#     # cim =  VectorSim(Num_rows,Num_Columns,mode=mode)\n",
    "#     # cim =  VectorSim(Num_rows,Num_Columns,mode=\"cs\")\n",
    "\n",
    "#     for n in range(N):\n",
    "#         for i in tqdm(range(Hout)):\n",
    "#             for j in range(Wout):\n",
    "#                 cout = np.zeros((num_tiles_columns * Num_Columns))\n",
    "#                 for col_idx in range(num_tiles_columns):\n",
    "#                     inp = input_vec[n,i,j,:,:]\n",
    "#                     # print(inp.shape)\n",
    "#                     w = crossbar_weights[:,col_idx,:,:]\n",
    "#                     # w = w.reshape(num_tiles_rows, Num_rows, Num_Columns)\n",
    "#                     # w = crossbar_weights.reshape(num_tiles_rows, Num_rows, Num_Columns)\n",
    "#                     # print(w.shape)\n",
    "\n",
    "#                     intermidiate_out = np.zeros((num_tiles_rows, Num_Columns))\n",
    "#                     for idx, vec in enumerate(inp):\n",
    "#                         weight = w[idx,:,:]\n",
    "#                         if checkboard and col_idx == num_tiles_columns - 1:\n",
    "#                             checkerboard_last_cols(weight, Num_Columns-Cout)\n",
    "#                         # print(weight)\n",
    "#                         _,out = _task((idx,vec),weight,Num_rows,Num_Columns,mode,False)\n",
    "#                         # cim.set_weights(weight)\n",
    "#                         # out = cim.run_vector(vec)\n",
    "#                         # # out = np.dot(vec, w[idx,:,:])\n",
    "#                         intermidiate_out[idx,:] = out\n",
    "#                     # print(intermidiate_out.shape)\n",
    "#                     cout_outs = np.sum(intermidiate_out, axis=0)\n",
    "#                     cout[col_idx*Num_Columns:(col_idx+1)*Num_Columns] = cout_outs\n",
    "#                     # if num_tiles_columns==1:\n",
    "#                     #     cout = cout_outs[:Cout]\n",
    "#                     # else\n",
    "#                 final_cout = np.ravel(cout[:Cout])\n",
    "#                 output[n,:,i,j] = final_cout\n",
    "#     return output\n",
    "# # out_loops  = conv2d_tiles(inputs, filters,Num_rows,Num_Columns, padding)\n",
    "# # print(np.array_equal(out_loops, ref.numpy()))\n",
    "# # print(out_loops-ref.numpy())\n",
    "# # print(\"Output shape:\", out_loops[0].shape, out_loops[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "id": "0ace1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossbar_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "id": "1e726c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_compliment(x):\n",
    "    Vp = (x == 1).int()\n",
    "    Vm = (x == -1).int()\n",
    "    return Vp, Vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "id": "51b7bf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
       "            1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.],\n",
       "          [ 1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
       "            1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.],\n",
       "          [ 1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
       "           -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.],\n",
       "          [-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
       "           -1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.],\n",
       "          [-1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "           -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.],\n",
       "          [ 1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "           -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.],\n",
       "          [-1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "           -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.],\n",
       "          [ 1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "           -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.],\n",
       "          [-1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "            1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.],\n",
       "          [ 1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "            1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.],\n",
       "          [ 1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
       "            1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
       "          [-1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "           -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
       "          [-1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "            1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.],\n",
       "          [ 1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "           -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.],\n",
       "          [-1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "           -1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.],\n",
       "          [-1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "           -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.],\n",
       "          [ 1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n",
       "            1., -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.],\n",
       "          [ 1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "           -1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.],\n",
       "          [-1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "           -1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.],\n",
       "          [-1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "            1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.],\n",
       "          [-1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "            1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.],\n",
       "          [ 1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
       "            1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.],\n",
       "          [-1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "            1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.],\n",
       "          [-1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,\n",
       "            1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.],\n",
       "          [-1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "            1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "            1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.],\n",
       "          [-1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "           -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],\n",
       "          [ 1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "            1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.]]]])"
      ]
     },
     "execution_count": 1066,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "96dadce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "id": "56b4c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=nn.functional.pad(inputs, (padding, padding, padding, padding), mode='constant', value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "id": "92d6f8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 24, 24])"
      ]
     },
     "execution_count": 1069,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compliment(x):\n",
    "    x = x.clone()\n",
    "    neg = -1*x\n",
    "    pos = x\n",
    "\n",
    "    pos[pos==-1] = 0\n",
    "    neg[neg==-1] = 0\n",
    "    return pos, neg\n",
    "\n",
    "# pos_inputs, neg_inputs = alt_compliment(inputs)\n",
    "# pos_filters, neg_filters = alt_compliment(filters)\n",
    "pos_inputs, neg_inputs = compliment(inputs)\n",
    "pos_filters, neg_filters = compliment(filters_b)\n",
    "# padding=1\n",
    "# pos_inputs = nn.functional.pad(pos_inputs, (padding, padding, padding, padding), mode='constant', value=1)\n",
    "# neg_inputs = nn.functional.pad(neg_inputs, (padding, padding, padding, padding), mode='constant', value=1)\n",
    "padding=0\n",
    "pos_ref = F.conv2d(pos_inputs, pos_filters, padding=padding)\n",
    "neg_ref = F.conv2d(neg_inputs, neg_filters, padding=padding)\n",
    "pos_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "993be4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "            1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.],\n",
      "          [ 1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
      "            1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.],\n",
      "          [ 1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
      "           -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.],\n",
      "          [-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
      "           -1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.],\n",
      "          [-1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "           -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.],\n",
      "          [ 1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,\n",
      "           -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.],\n",
      "          [-1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
      "           -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.],\n",
      "          [ 1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
      "           -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.],\n",
      "          [-1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
      "            1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.],\n",
      "          [ 1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
      "            1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.],\n",
      "          [ 1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "            1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
      "          [-1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "           -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
      "          [-1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
      "            1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.],\n",
      "          [ 1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,\n",
      "           -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.],\n",
      "          [-1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
      "           -1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.],\n",
      "          [-1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "           -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.],\n",
      "          [ 1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "            1., -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.],\n",
      "          [ 1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
      "           -1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.],\n",
      "          [-1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
      "           -1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
      "            1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.],\n",
      "          [-1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
      "            1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.],\n",
      "          [ 1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
      "            1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.],\n",
      "          [-1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,\n",
      "            1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.],\n",
      "          [-1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,\n",
      "            1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.],\n",
      "          [-1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
      "            1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,\n",
      "            1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.],\n",
      "          [-1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
      "           -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.],\n",
      "          [ 1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
      "            1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "           1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.],\n",
      "          [1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
      "           0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "          [1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "           1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "          [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "           0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.],\n",
      "          [0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "           1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
      "          [1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "           1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.],\n",
      "          [0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "           0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
      "          [1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "           0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.],\n",
      "          [0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "           0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
      "          [1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "           1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.],\n",
      "          [1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "           0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.],\n",
      "          [0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
      "           0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "          [0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
      "           0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "           1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.],\n",
      "          [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "           1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "          [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "           1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
      "          [1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "           1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
      "          [1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "           1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "          [0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "           1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
      "          [0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "           1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "           0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "          [1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "           1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.],\n",
      "          [0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "           0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
      "          [0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "           1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
      "          [0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "           1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.],\n",
      "          [1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "           1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.],\n",
      "          [0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
      "           0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "           1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "           0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.],\n",
      "          [0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "           1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
      "          [0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "           0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "          [1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "           1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.],\n",
      "          [1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "           0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "          [0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "           0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.],\n",
      "          [1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "           1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.],\n",
      "          [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "           1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
      "          [1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
      "           1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "           0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "          [0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "           1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "          [1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "           1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "           1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
      "          [0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "           0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.],\n",
      "          [1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "           0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "           0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.],\n",
      "          [0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
      "           0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.],\n",
      "          [0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "           0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "          [1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "           0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "          [1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "           0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.],\n",
      "          [1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "           1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
      "          [0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "           0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "          [1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
      "           1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "          [1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "           0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "          [1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "           0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
      "          [1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "           1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "          [0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "           0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(pos_inputs)\n",
    "print(neg_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "fa017183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -3.,  -3.,   1.,  ...,   3.,   1.,   3.],\n",
       "          [ -7.,  -5.,  -1.,  ...,   1.,   1.,   7.],\n",
       "          [ -3.,  -3.,   3.,  ...,  -5.,  -5.,  -9.],\n",
       "          ...,\n",
       "          [  1.,   1.,   5.,  ...,   1.,  -3.,  -1.],\n",
       "          [  5.,   7.,   3.,  ...,  -5.,  -7.,  -1.],\n",
       "          [  3.,   3.,   1.,  ...,  -3.,  -1.,   3.]],\n",
       "\n",
       "         [[  1.,  -3.,   1.,  ...,   3.,  -3.,  -1.],\n",
       "          [ -7.,  -1.,  -5.,  ...,  -3.,   1.,  -5.],\n",
       "          [  1.,  -3.,  -9.,  ...,   3.,   3.,   3.],\n",
       "          ...,\n",
       "          [ -7.,   5.,   1.,  ...,   9.,   5.,  -1.],\n",
       "          [ -3.,  -5.,   3.,  ...,  11.,   5.,   3.],\n",
       "          [ -1.,   3.,   5.,  ...,   1.,  -5.,   3.]],\n",
       "\n",
       "         [[ -5.,  -1.,   3.,  ...,   5.,   3.,   1.],\n",
       "          [ -1.,   1.,   5.,  ...,  -5.,  -9.,  -3.],\n",
       "          [  7.,   7.,  -3.,  ...,  -7.,  -7.,  -3.],\n",
       "          ...,\n",
       "          [  3.,  -1.,  -1.,  ...,  -5.,  -1.,   1.],\n",
       "          [  3.,   1.,   1.,  ...,  -3.,  -9.,  -3.],\n",
       "          [  1.,  -3.,   3.,  ...,   7.,   1.,  -3.]],\n",
       "\n",
       "         [[ -3., -11.,  -7.,  ...,  -1.,   1.,  -5.],\n",
       "          [ -3.,  -9.,  -9.,  ...,   1.,   1.,  -5.],\n",
       "          [  1., -11., -13.,  ...,   3.,   3.,  -9.],\n",
       "          ...,\n",
       "          [ -3.,   1.,   9.,  ...,   5.,   5.,   3.],\n",
       "          [  5.,   3.,   7.,  ...,   3.,   1.,  -1.],\n",
       "          [ -1.,   3.,   9.,  ...,   1.,   3.,   3.]],\n",
       "\n",
       "         [[  1.,   1.,  -7.,  ...,   7.,   1.,  -1.],\n",
       "          [  5.,   3.,  -9.,  ...,   1.,  -3.,   7.],\n",
       "          [  5.,   5., -13.,  ...,  -1.,   3.,   7.],\n",
       "          ...,\n",
       "          [ -3., -11.,   1.,  ...,   1.,   1.,   3.],\n",
       "          [ -3.,  -5.,   3.,  ...,   3.,  -3.,  -1.],\n",
       "          [ -5.,  -5.,   1.,  ...,   1.,  -1.,  -1.]],\n",
       "\n",
       "         [[  5.,   1.,   1.,  ...,   3.,  -3.,  -1.],\n",
       "          [ -3.,  -1.,   3.,  ...,  13.,   1.,   3.],\n",
       "          [ -7.,  -7.,  -5.,  ...,   3.,  -1.,   3.],\n",
       "          ...,\n",
       "          [ -3.,  -3.,  -3.,  ...,   5.,   9.,   3.],\n",
       "          [  5.,  -1.,  -5.,  ...,  -1.,   5.,   7.],\n",
       "          [ -5.,   3.,   1.,  ...,  -7.,  -5.,  -1.]]]])"
      ]
     },
     "execution_count": 1071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = nn.functional.conv2d(inputs, filters_b, padding=0)\n",
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "id": "c63bdd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -3.,  -3.,   1.,  ...,   3.,   1.,   3.],\n",
       "          [ -7.,  -5.,  -1.,  ...,   1.,   1.,   7.],\n",
       "          [ -3.,  -3.,   3.,  ...,  -5.,  -5.,  -9.],\n",
       "          ...,\n",
       "          [  1.,   1.,   5.,  ...,   1.,  -3.,  -1.],\n",
       "          [  5.,   7.,   3.,  ...,  -5.,  -7.,  -1.],\n",
       "          [  3.,   3.,   1.,  ...,  -3.,  -1.,   3.]],\n",
       "\n",
       "         [[  1.,  -3.,   1.,  ...,   3.,  -3.,  -1.],\n",
       "          [ -7.,  -1.,  -5.,  ...,  -3.,   1.,  -5.],\n",
       "          [  1.,  -3.,  -9.,  ...,   3.,   3.,   3.],\n",
       "          ...,\n",
       "          [ -7.,   5.,   1.,  ...,   9.,   5.,  -1.],\n",
       "          [ -3.,  -5.,   3.,  ...,  11.,   5.,   3.],\n",
       "          [ -1.,   3.,   5.,  ...,   1.,  -5.,   3.]],\n",
       "\n",
       "         [[ -5.,  -1.,   3.,  ...,   5.,   3.,   1.],\n",
       "          [ -1.,   1.,   5.,  ...,  -5.,  -9.,  -3.],\n",
       "          [  7.,   7.,  -3.,  ...,  -7.,  -7.,  -3.],\n",
       "          ...,\n",
       "          [  3.,  -1.,  -1.,  ...,  -5.,  -1.,   1.],\n",
       "          [  3.,   1.,   1.,  ...,  -3.,  -9.,  -3.],\n",
       "          [  1.,  -3.,   3.,  ...,   7.,   1.,  -3.]],\n",
       "\n",
       "         [[ -3., -11.,  -7.,  ...,  -1.,   1.,  -5.],\n",
       "          [ -3.,  -9.,  -9.,  ...,   1.,   1.,  -5.],\n",
       "          [  1., -11., -13.,  ...,   3.,   3.,  -9.],\n",
       "          ...,\n",
       "          [ -3.,   1.,   9.,  ...,   5.,   5.,   3.],\n",
       "          [  5.,   3.,   7.,  ...,   3.,   1.,  -1.],\n",
       "          [ -1.,   3.,   9.,  ...,   1.,   3.,   3.]],\n",
       "\n",
       "         [[  1.,   1.,  -7.,  ...,   7.,   1.,  -1.],\n",
       "          [  5.,   3.,  -9.,  ...,   1.,  -3.,   7.],\n",
       "          [  5.,   5., -13.,  ...,  -1.,   3.,   7.],\n",
       "          ...,\n",
       "          [ -3., -11.,   1.,  ...,   1.,   1.,   3.],\n",
       "          [ -3.,  -5.,   3.,  ...,   3.,  -3.,  -1.],\n",
       "          [ -5.,  -5.,   1.,  ...,   1.,  -1.,  -1.]],\n",
       "\n",
       "         [[  5.,   1.,   1.,  ...,   3.,  -3.,  -1.],\n",
       "          [ -3.,  -1.,   3.,  ...,  13.,   1.,   3.],\n",
       "          [ -7.,  -7.,  -5.,  ...,   3.,  -1.,   3.],\n",
       "          ...,\n",
       "          [ -3.,  -3.,  -3.,  ...,   5.,   9.,   3.],\n",
       "          [  5.,  -1.,  -5.,  ...,  -1.,   5.,   7.],\n",
       "          [ -5.,   3.,   1.,  ...,  -7.,  -5.,  -1.]]]])"
      ]
     },
     "execution_count": 1072,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I  = pos_ref + neg_ref\n",
    "out = 2*I - Kh*Kw*CIN\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "f30a235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(pos_ref, neg_ref,Kh, Kw, CIN):\n",
    "    I = pos_ref + neg_ref\n",
    "    out = 2*I - Kh*Kw*CIN\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "66ce76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_inferenece(x,w, Num_rows, Num_Columns, padding=0, mode=\"gs\", checkboard=False, workers=8):\n",
    "    N, Cin, H, W     = x.shape\n",
    "    Cout, _, Kh, Kw  = w.shape\n",
    "    pos_inputs, neg_inputs = compliment(x)\n",
    "    pos_filters, neg_filters = compliment(w)\n",
    "    pos_cim = conv2d_tiles(pos_inputs,pos_filters,Num_rows,Num_Columns,padding=padding,mode=mode,checkboard=checkboard,workers=workers)\n",
    "    neg_cim = conv2d_tiles(neg_inputs,neg_filters,Num_rows,Num_Columns,padding=padding,mode=mode,checkboard=checkboard,workers=workers)\n",
    "    output = get_output(pos_cim, neg_cim, Kh, Kw, Cin)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "84be042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_cim_gs = conv_inferenece(inputs,filters_b, Num_rows, Num_Columns, padding=padding, mode=\"gs\", checkboard=False, workers=8)\n",
    "# out_cim_cs = conv_inferenece(inputs,filters_b, Num_rows, Num_Columns, padding=padding, mode=\"cs\", checkboard=False, workers=8)\n",
    "# out_cim_gs_check = conv_inferenece(inputs,filters_b, Num_rows, Num_Columns, padding=padding, mode=\"gs\", checkboard=True, workers=8)\n",
    "# out_cim_cs_check = conv_inferenece(inputs,filters_b, Num_rows, Num_Columns, padding=padding, mode=\"cs\", checkboard=True, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "00fab3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = \"gs\"\n",
    "# pos_ref_cim_gs = conv2d_tiles(pos_inputs,pos_filters,Num_rows,Num_Columns,mode=mode)\n",
    "# neg_ref_cim_gs = conv2d_tiles(neg_inputs,neg_filters,Num_rows,Num_Columns,mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "89ad604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = \"cs\"\n",
    "# pos_ref_cim_cs = conv2d_tiles(pos_inputs,pos_filters,Num_rows,Num_Columns,mode=mode)\n",
    "# neg_ref_cim_cs = conv2d_tiles(neg_inputs,neg_filters,Num_rows,Num_Columns,mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "8e575186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = \"gs\"\n",
    "# pos_ref_cim_gs_check = conv2d_tiles(pos_inputs,pos_filters,Num_rows,Num_Columns,mode=mode,checkboard=True)\n",
    "# neg_ref_cim_gs_check = conv2d_tiles(neg_inputs,neg_filters,Num_rows,Num_Columns,mode=mode,checkboard=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "7bd28c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = \"cs\"\n",
    "# pos_ref_cim_cs_check = conv2d_tiles(pos_inputs,pos_filters,Num_rows,Num_Columns,mode=mode,checkboard=True)\n",
    "# neg_ref_cim_cs_check = conv2d_tiles(neg_inputs,neg_filters,Num_rows,Num_Columns,mode=mode,checkboard=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "id": "c5d3172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = ref.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "id": "a8a07c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_cim_gs = get_output(pos_ref_cim_gs, neg_ref_cim_gs,Kh, Kw, CIN)\n",
    "# out_cim_cs = get_output(pos_ref_cim_cs, neg_ref_cim_cs,Kh, Kw, CIN)\n",
    "# out_cim_gs_check = get_output(pos_ref_cim_gs_check, neg_ref_cim_gs_check,Kh, Kw, CIN)\n",
    "# out_cim_cs_check = get_output(pos_ref_cim_cs_check, neg_ref_cim_cs_check,Kh, Kw, CIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "id": "3bc8fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_cim_gs = pos_ref_cim_gs+neg_ref_cim_gs\n",
    "# out_cim_gs = 2*out_cim_gs - Kh*Kw*CIN\n",
    "# out_cim_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "id": "4ae519e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# out_cim_cs = pos_ref_cim_cs+neg_ref_cim_cs\n",
    "# out_cim_cs = 2*out_cim_cs - Kh*Kw*CIN\n",
    "# out_cim_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "id": "c9e06e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array_equal(out,ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "id": "e1a68f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array_equal(out_cim,ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "id": "b1b5e893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -3.,  -3.,   1., ...,   3.,   1.,   3.],\n",
       "         [ -7.,  -5.,  -1., ...,   1.,   1.,   7.],\n",
       "         [ -3.,  -3.,   3., ...,  -5.,  -5.,  -9.],\n",
       "         ...,\n",
       "         [  1.,   1.,   5., ...,   1.,  -3.,  -1.],\n",
       "         [  5.,   7.,   3., ...,  -5.,  -7.,  -1.],\n",
       "         [  3.,   3.,   1., ...,  -3.,  -1.,   3.]],\n",
       "\n",
       "        [[  1.,  -3.,   1., ...,   3.,  -3.,  -1.],\n",
       "         [ -7.,  -1.,  -5., ...,  -3.,   1.,  -5.],\n",
       "         [  1.,  -3.,  -9., ...,   3.,   3.,   3.],\n",
       "         ...,\n",
       "         [ -7.,   5.,   1., ...,   9.,   5.,  -1.],\n",
       "         [ -3.,  -5.,   3., ...,  11.,   5.,   3.],\n",
       "         [ -1.,   3.,   5., ...,   1.,  -5.,   3.]],\n",
       "\n",
       "        [[ -5.,  -1.,   3., ...,   5.,   3.,   1.],\n",
       "         [ -1.,   1.,   5., ...,  -5.,  -9.,  -3.],\n",
       "         [  7.,   7.,  -3., ...,  -7.,  -7.,  -3.],\n",
       "         ...,\n",
       "         [  3.,  -1.,  -1., ...,  -5.,  -1.,   1.],\n",
       "         [  3.,   1.,   1., ...,  -3.,  -9.,  -3.],\n",
       "         [  1.,  -3.,   3., ...,   7.,   1.,  -3.]],\n",
       "\n",
       "        [[ -3., -11.,  -7., ...,  -1.,   1.,  -5.],\n",
       "         [ -3.,  -9.,  -9., ...,   1.,   1.,  -5.],\n",
       "         [  1., -11., -13., ...,   3.,   3.,  -9.],\n",
       "         ...,\n",
       "         [ -3.,   1.,   9., ...,   5.,   5.,   3.],\n",
       "         [  5.,   3.,   7., ...,   3.,   1.,  -1.],\n",
       "         [ -1.,   3.,   9., ...,   1.,   3.,   3.]],\n",
       "\n",
       "        [[  1.,   1.,  -7., ...,   7.,   1.,  -1.],\n",
       "         [  5.,   3.,  -9., ...,   1.,  -3.,   7.],\n",
       "         [  5.,   5., -13., ...,  -1.,   3.,   7.],\n",
       "         ...,\n",
       "         [ -3., -11.,   1., ...,   1.,   1.,   3.],\n",
       "         [ -3.,  -5.,   3., ...,   3.,  -3.,  -1.],\n",
       "         [ -5.,  -5.,   1., ...,   1.,  -1.,  -1.]],\n",
       "\n",
       "        [[  5.,   1.,   1., ...,   3.,  -3.,  -1.],\n",
       "         [ -3.,  -1.,   3., ...,  13.,   1.,   3.],\n",
       "         [ -7.,  -7.,  -5., ...,   3.,  -1.,   3.],\n",
       "         ...,\n",
       "         [ -3.,  -3.,  -3., ...,   5.,   9.,   3.],\n",
       "         [  5.,  -1.,  -5., ...,  -1.,   5.,   7.],\n",
       "         [ -5.,   3.,   1., ...,  -7.,  -5.,  -1.]]]],\n",
       "      shape=(1, 6, 24, 24), dtype=float32)"
      ]
     },
     "execution_count": 1086,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "id": "646fa8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref = ref.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "id": "204234bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_cim_gs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "347daa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with np.printoptions(threshold=np.inf):\n",
    "#     out_cim_gs = out_cim_gs.numpy()\n",
    "#     diff =out_cim_gs-ref \n",
    "#     print(diff)\n",
    "#     print(np.mean(np.abs(diff)))\n",
    "\n",
    "#     # print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "id": "e26a93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with np.printoptions(threshold=np.inf):\n",
    "#     out_cim_cs = out_cim_cs.numpy()\n",
    "#     diff =out_cim_cs-ref\n",
    "#     print(diff)\n",
    "#     # print(np.mean(diff))\n",
    "#     print(np.mean(np.abs(diff)))\n",
    "\n",
    "#     # print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "id": "5d7cb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with np.printoptions(threshold=np.inf):\n",
    "#     out_cim_gs_check = out_cim_gs_check.numpy()\n",
    "#     diff =out_cim_gs_check-ref\n",
    "#     print(diff)\n",
    "#     print(np.mean(np.abs(diff)))\n",
    "#     # print(out_cim_gs_check-ref)\n",
    "#     # print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "id": "01f5d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with np.printoptions(threshold=np.inf):\n",
    "#     out_cim_cs_check = out_cim_cs_check.numpy()\n",
    "#     diff =out_cim_cs_check-ref\n",
    "#     print(diff)\n",
    "#     print(np.mean(np.abs(diff)))\n",
    "#     # print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "id": "1a32b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizeConv2dInference(nn.Conv2d):\n",
    "    def __init__(self,\n",
    "                 in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, dilation=1, groups=1,\n",
    "                 bias=True,\n",
    "                 Num_rows=4, Num_Columns=4,\n",
    "                 mode=\"gs\", checkboard=False, workers=8):\n",
    "        super().__init__(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            stride=stride, padding=padding,\n",
    "            dilation=dilation, groups=groups, bias=bias\n",
    "        )\n",
    "        # parameters for custom tiled conv\n",
    "        self.Num_rows    = Num_rows\n",
    "        self.Num_Columns = Num_Columns\n",
    "        self.mode        = mode\n",
    "        self.checkboard  = checkboard\n",
    "        self.workers     = workers\n",
    "\n",
    "    def forward(self, input):\n",
    "        # binarize inputs (but keep first 3-channel inputs full-precision)\n",
    "        if input.size(1) != 3:\n",
    "            input_b = binarized(input)\n",
    "        else:\n",
    "            input_b = input\n",
    "\n",
    "        # binarize weights\n",
    "        weight_b = binarized(self.weight)\n",
    "\n",
    "        # use custom inference routine instead of F.conv2d\n",
    "        padding = self.padding[0] if isinstance(self.padding, tuple) else self.padding\n",
    "        out = conv_inferenece(\n",
    "            input_b, weight_b,\n",
    "            self.Num_rows, self.Num_Columns,\n",
    "            padding=padding,\n",
    "            mode=self.mode,\n",
    "            checkboard=self.checkboard,\n",
    "            workers=self.workers\n",
    "        )\n",
    "\n",
    "        # add bias if present\n",
    "        if self.bias is not None:\n",
    "            # store original bias for potential gradient updates, etc.\n",
    "            self.bias.org = self.bias.data.clone()\n",
    "            out = out + self.bias.view(1, -1, 1, 1).expand_as(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "id": "ef8ed602",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = BinarizeConv2dInference(CIN, COUT, kernel_size=Kh,Num_rows=Num_rows, Num_Columns=Num_Columns,bias=False, mode=\"cs\", checkboard=True, workers=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "id": "99f381f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.weight = nn.Parameter(model.conv1.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "id": "8139f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_conv(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "id": "95396290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 1097,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "id": "2d42a133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.017361111111111112)"
      ]
     },
     "execution_count": 1098,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(out.detach().numpy() - ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "id": "3f7e9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_tile(b,i,j,N,num_tiles_columns, Num_rows, Num_Columns,vec, weight, mode=\"gs\", checkboard=False):\n",
    "#     if checkboard and j == (num_tiles_columns - 1):\n",
    "#         print(Num_Columns - N % Num_Columns)\n",
    "#         checkerboard_last_cols(weight, Num_Columns - N % Num_Columns)\n",
    "#     _, out_vec = _task(((i,j), vec), weight, Num_rows, Num_Columns, mode, False)\n",
    "#     return ((b,i,j),out_vec)\n",
    "\n",
    "# def linear(x,w, Num_rows, Num_Columns, mode=\"gs\", checkboard=False, workers=8):\n",
    "#     # print(x.shape, w.shape)\n",
    "#     # single = x.ndim == 1\n",
    "#     # if single:\n",
    "#     #     x = x[None, :]\n",
    "#     B, Μ = x.shape\n",
    "#     M, N= w.shape\n",
    "#     num_tiles_columns = int(np.ceil(N / Num_Columns)) \n",
    "#     num_tiles_rows = int(np.ceil(M / Num_rows))\n",
    "#     print(num_tiles_rows,num_tiles_columns,  Num_rows, Num_Columns)\n",
    "#     out = np.zeros((B, num_tiles_columns*Num_Columns), dtype=int)\n",
    "\n",
    "#     crossbar_weights = np.zeros((num_tiles_rows, num_tiles_columns, Num_rows, Num_Columns), dtype=bool)\n",
    "#     for i in range(num_tiles_rows):\n",
    "#         for j in range(num_tiles_columns):\n",
    "#             start_row = i * Num_rows\n",
    "#             end_row = min(start_row + Num_rows, M)\n",
    "#             start_col = j * Num_Columns\n",
    "#             end_col = min(start_col + Num_Columns, N)\n",
    "#             w_tile = w[start_row:end_row, start_col:end_col]\n",
    "#             crossbar_weights[i, j, :w_tile.shape[0], :w_tile.shape[1]] = w_tile\n",
    "    \n",
    "#     input_vec = np.zeros((B, num_tiles_rows, Num_rows), dtype=bool)\n",
    "#     for b in range(B):\n",
    "#         for i in range(num_tiles_rows):\n",
    "#             start_row = i * Num_rows\n",
    "#             end_row = min(start_row + Num_rows, M)\n",
    "#             # print(start_row, end_row)\n",
    "#             input_vec[b, i, :end_row] = x[b, start_row:end_row]\n",
    "    \n",
    "#     for b in range(B):\n",
    "#         for i in range(num_tiles_rows):\n",
    "#             for j in range(num_tiles_columns):\n",
    "#                 vec = input_vec[b, i, :]\n",
    "#                 W = crossbar_weights[i, j, :, :]\n",
    "#                 # if checkboard and j == num_tiles_columns - 1:\n",
    "#                 #     # print(Num_Columns - N % Num_Columns)\n",
    "#                 #     checkerboard_last_cols(W, Num_Columns - N % Num_Columns)\n",
    "#                 _, out_vec = one_tile(b,i,j,N,num_tiles_columns, Num_rows, Num_Columns,vec, W, mode=mode, checkboard=checkboard)\n",
    "\n",
    "#                 # _, out_vec = _task(((i,j), vec), W, Num_rows, Num_Columns, mode, False)\n",
    "#                 out[b, j*Num_Columns:(j+1)*Num_Columns] += out_vec\n",
    "#     output = torch.from_numpy(out)\n",
    "\n",
    "#     return output[:, :N]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "id": "45e9de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "def _process_linear_tile(args):\n",
    "    \"\"\"\n",
    "    Worker for one tile of the linear layer.\n",
    "    Returns (b, j, out_vec) same shape as one_tile would produce.\n",
    "    \"\"\"\n",
    "    b, i, j, N, num_tiles_columns, Num_rows, Num_Columns, vec, W, mode, checkboard = args\n",
    "    if checkboard and j == (num_tiles_columns - 1):\n",
    "        # apply checkerboard correction on the last column tile\n",
    "        checkerboard_last_cols(W, Num_Columns - N % Num_Columns)\n",
    "    _, out_vec = _task(((i, j), vec), W, Num_rows, Num_Columns, mode, False)\n",
    "    return b, j, out_vec\n",
    "\n",
    "def linear_parallel(x, w,\n",
    "                    Num_rows, Num_Columns,\n",
    "                    mode=\"gs\", checkboard=False,\n",
    "                    workers=8):\n",
    "    \"\"\"\n",
    "    x: torch tensor or numpy array of shape (B, M)\n",
    "    w: numpy array of shape (M, N)\n",
    "    returns torch tensor of shape (B, N)\n",
    "    \"\"\"\n",
    "    # ensure numpy\n",
    "    x_np = x.detach().cpu().numpy() if isinstance(x, torch.Tensor) else x\n",
    "    B, M = x_np.shape\n",
    "    M2, N = w.shape\n",
    "    assert M == M2, \"Input/features mismatch\"\n",
    "\n",
    "    # how many tiles we need\n",
    "    num_tiles_columns = int(np.ceil(N / Num_Columns))\n",
    "    num_tiles_rows    = int(np.ceil(M / Num_rows))\n",
    "\n",
    "    # build tiled weight array\n",
    "    crossbar_weights = np.zeros((num_tiles_rows, num_tiles_columns, Num_rows, Num_Columns),\n",
    "                                dtype=bool)\n",
    "    for i in range(num_tiles_rows):\n",
    "        for j in range(num_tiles_columns):\n",
    "            r0, r1 = i*Num_rows, min((i+1)*Num_rows, M)\n",
    "            c0, c1 = j*Num_Columns, min((j+1)*Num_Columns, N)\n",
    "            w_tile = w[r0:r1, c0:c1]\n",
    "            crossbar_weights[i, j, :w_tile.shape[0], :w_tile.shape[1]] = w_tile\n",
    "\n",
    "    # build tiled input array\n",
    "    input_vec = np.zeros((B, num_tiles_rows, Num_rows), dtype=bool)\n",
    "    for b in range(B):\n",
    "        for i in range(num_tiles_rows):\n",
    "            r0, r1 = i*Num_rows, min((i+1)*Num_rows, M)\n",
    "            input_vec[b, i, :r1-r0] = x_np[b, r0:r1]\n",
    "\n",
    "    # prepare output accumulator (numpy)\n",
    "    out = np.zeros((B, num_tiles_columns * Num_Columns), dtype=int)\n",
    "\n",
    "    # pack all tile arguments\n",
    "    tasks = []\n",
    "    for b in range(B):\n",
    "        for i in range(num_tiles_rows):\n",
    "            for j in range(num_tiles_columns):\n",
    "                vec = input_vec[b, i, :]\n",
    "                W   = crossbar_weights[i, j, :, :]\n",
    "                tasks.append((b, i, j, N, num_tiles_columns,\n",
    "                              Num_rows, Num_Columns,\n",
    "                              vec, W, mode, checkboard))\n",
    "\n",
    "    # parallel execution\n",
    "    with ProcessPoolExecutor(max_workers=workers) as exe:\n",
    "        future_to_tile = {\n",
    "            exe.submit(_process_linear_tile, args): args[:3]\n",
    "            for args in tasks\n",
    "        }\n",
    "        for fut in as_completed(future_to_tile):\n",
    "            b, j, out_vec = fut.result()\n",
    "            start = j * Num_Columns\n",
    "            end   = start + Num_Columns\n",
    "            out[b, start:end] += out_vec\n",
    "\n",
    "    # slice off any padding columns and wrap in torch.Tensor\n",
    "    out = out[:, :N]\n",
    "    return torch.from_numpy(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "id": "dc52a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = model.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "id": "eb40e255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 256])"
      ]
     },
     "execution_count": 1102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "id": "1d6525f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters = torch.randn(COUT, CIN, Kh, Kw)\n",
    "B = 1\n",
    "fc_inputs = torch.randn(B, shape[1])\n",
    "fc_inputs = binarized(fc_inputs)\n",
    "\n",
    "fc_weights = torch.randn(shape[0], shape[1])\n",
    "fc_weights = binarized(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "id": "e193f2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16., -20.,  14.,  18.,  -4., -24.,  32.,   6.,  16.,  12.,  16., -10.,\n",
       "         -24.,  -8.,  14.,  10.,  -8., -18.,  10., -18.,  -6., -20.,  20.,  22.,\n",
       "          26.,  38.,   8.,  14.,   6.,  12., -10.,   6., -42., -16., -14.,  32.,\n",
       "         -28.,  18., -14., -26.,   8., -10.,  24., -42., -14.,  18.,  12., -22.,\n",
       "          30.,  -6.,  20., -12.,  14.,  26.,  16.,   8.,  -6.,  -4.,   8., -12.,\n",
       "         -10.,   6., -22.,   4.,  12., -14.,  12.,   6.,   0.,   8.,   2.,   4.,\n",
       "         -12.,   8., -40., -12.,  18., -10.,  22.,   6.,   0.,  -6.,   4.,  -6.,\n",
       "          20.,  20., -18., -10.,  -6.,  -2.,  16., -14., -24.,  -4.,  -6., -16.,\n",
       "         -10., -16.,  -8.,  -4.,  20.,  16., -16.,   0.,   4., -28.,  -4.,  16.,\n",
       "           6.,  -8.,  22.,  20.,   8.,   0.,  16.,  16.,  26.,   2.,  -6.,  20.]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.linear(fc_inputs, fc_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "6cfd7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_output(pos, neg, M):\n",
    "    I = pos + neg\n",
    "    out = 2*I - M\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "37f2021a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_pos_inputs, fc_neg_inputs = compliment(fc_inputs)\n",
    "fc_pos_filters, fc_neg_filters = compliment(fc_weights)\n",
    "\n",
    "pos_rf_fc = nn.functional.linear(fc_pos_inputs, fc_pos_filters)\n",
    "neg_rf_fc = nn.functional.linear(fc_neg_inputs, fc_neg_filters)\n",
    "\n",
    "out_fc = get_fc_output(pos_rf_fc, neg_rf_fc, shape[1])\n",
    "torch.equal(out_fc, nn.functional.linear(fc_inputs, fc_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ff4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_inferenece(x,w, Num_rows, Num_Columns, mode=\"gs\", checkboard=False, workers=8):\n",
    "    shape = w.shape\n",
    "    pos_inputs, neg_inputs = compliment(x)\n",
    "    pos_filters, neg_filters = compliment(w)\n",
    "    pos_cim = linear_parallel(pos_inputs.numpy(),pos_filters.detach().numpy().T, Num_rows, Num_Columns, mode=mode, checkboard=checkboard, workers=workers)\n",
    "    neg_cim = linear_parallel(neg_inputs.numpy(),neg_filters.detach().numpy().T, Num_rows, Num_Columns, mode=mode, checkboard=checkboard, workers=workers)\n",
    "    # pos_cim = linear(pos_inputs.numpy(),pos_filters.detach().numpy().T, Num_rows, Num_Columns, mode=mode, checkboard=checkboard, workers=8)\n",
    "    # neg_cim = linear(neg_inputs.numpy(),neg_filters.detach().numpy().T, Num_rows, Num_Columns, mode=mode, checkboard=checkboard, workers=8)\n",
    "    output = get_fc_output(pos_cim, neg_cim, shape[1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "d9e94e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cim_fc = linear_inferenece(fc_inputs, fc_weights, Num_rows, Num_Columns, mode=\"cs\", checkboard=True, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "8191e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_cim = linear(fc_pos_inputs.numpy(),fc_pos_filters.detach().numpy().T, Num_rows, Num_Columns, mode=\"cs\", checkboard=True, workers=8)\n",
    "# neg_cim = linear(fc_neg_inputs.numpy(),fc_neg_filters.detach().numpy().T, Num_rows, Num_Columns, mode=\"cs\", checkboard=True, workers=8)\n",
    "\n",
    "# out_cim_fc = get_fc_output(pos_cim, neg_cim, shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "3837a049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16, -20,  14,  18,  -4, -24,  32,   6,  14,  14,  16, -12, -24,  -8,\n",
       "          14,   8,  -8, -18,   8, -18,  -6, -20,  20,  22,  26,  36,   8,  14,\n",
       "           6,  14, -10,   8, -42, -16, -14,  32, -28,  18, -12, -26,   8, -10,\n",
       "          24, -42, -14,  20,  14, -24,  30,  -6,  20, -12,  14,  26,  16,   8,\n",
       "          -6,  -2,   8, -12, -10,   6, -20,   4,  12, -14,  12,   8,   0,   8,\n",
       "           0,   4, -10,   8, -40, -12,  18, -10,  22,   6,   0,  -6,   4,  -6,\n",
       "          20,  20, -18, -10,  -6,   0,  16, -14, -24,  -4,  -6, -14, -10, -16,\n",
       "          -8,  -4,  20,  16, -14,   0,   4, -28,  -4,  16,   6,  -6,  22,  20,\n",
       "           8,   0,  18,  16,  26,   2,  -6,  20]])"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_cim_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "id": "165278c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 1111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_cim_fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "id": "7e1072ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  2.,  0., -2.,  0.,  0.,\n",
       "          0., -2.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,\n",
       "          0.,  2.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  2.,  2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  2.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n",
       "         -2.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n",
       "          0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 1112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_cim_fc - out_fc.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizeLinearInference(nn.Linear):\n",
    "\n",
    "    def __init__(self, in_features, out_features,Num_rows,Num_Columns,mode=\"gs\",checkboard=False,workers=8, bias=True, device=None, dtype=None):\n",
    "        # super(BinarizeLinear, self).__init__(*kargs, **kwargs)\n",
    "        super().__init__(in_features, out_features, bias=bias, device=None, dtype=None)\n",
    "        self.Num_rows    = Num_rows\n",
    "        self.Num_Columns = Num_Columns\n",
    "        self.mode        = mode\n",
    "        self.checkboard  = checkboard\n",
    "        self.workers     = workers\n",
    "    def forward(self, input):\n",
    "        # print(input.size(1))\n",
    "\n",
    "        # if input.size(1) != 784:\n",
    "        input_b=binarized(input)\n",
    "        weight_b=binarized(self.weight)\n",
    "        out = linear_inferenece(input_b, weight_b, self.Num_rows, self.Num_Columns, mode=self.mode, checkboard=self.checkboard, workers=self.workers)\n",
    "        # out = nn.functional.linear(input_b,weight_b)6\n",
    "        if not self.bias is None:\n",
    "            self.bias.org=self.bias.data.clone()\n",
    "            out += self.bias.view(1, -1).expand_as(out)\n",
    "        # print(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "id": "4258071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc = BinarizeLinearInference(shape[1], shape[0],bias=False, Num_rows=Num_rows, Num_Columns=Num_Columns, mode=\"cs\", checkboard=True, workers=8)\n",
    "\n",
    "model_fc.weight = nn.Parameter(model.fc1.weight)\n",
    "\n",
    "out_cim_fc = model_fc(fc_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "id": "d7a4bb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  2.,  0., -2.,  0.,  0.,\n",
       "          0., -2.,  0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,\n",
       "          0.,  2.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  2.,  2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  2.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n",
       "         -2.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n",
       "          0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 1127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_cim_fc - out_fc.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "id": "2e0348ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.36666667)"
      ]
     },
     "execution_count": 1128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = out_cim_fc - out_fc.detach()\n",
    "\n",
    "np.mean(np.abs(diff.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
